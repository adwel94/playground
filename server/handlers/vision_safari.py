import asyncio
import json
import os
from fastapi import WebSocket
from typing import Dict, Any, List

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from pydantic import BaseModel, Field

# --- ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ë„êµ¬(Action)ì˜ ìŠ¤í‚¤ë§ˆ ì •ì˜ ---
class MoveAction(BaseModel):
    """Move the player in the game grid."""
    direction: str = Field(description="The direction to move: 'UP', 'DOWN', 'LEFT', 'RIGHT'")
    steps: int = Field(default=1, description="Number of tiles to move")
    reason: str = Field(description="Why this move is chosen based on visual analysis")

class IdleAction(BaseModel):
    """Stop moving when the goal is reached or no move is possible."""
    reason: str = Field(description="Why the agent is stopping")

# --- ì—ì´ì „íŠ¸ ì„¸ì…˜ ê´€ë¦¬ í´ë˜ìŠ¤ ---
class SafariAgentSession:
    def __init__(self):
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            temperature=0
        )
        # 1. Memory êµ¬ì„±
        self.memory = ConversationBufferMemory(return_messages=True)
        
        # 2. Tool Binding (Structured Output)
        # ëª¨ë¸ì´ MoveAction ë˜ëŠ” IdleAction ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ë„ë¡ ê°•ì œ
        self.agent_with_tools = self.llm.bind_tools([MoveAction, IdleAction])
        
        self.last_image_data = None
        self.current_goal = ""

    async def decide_next_action(self, user_command: str, image_base64: str) -> Dict[str, Any]:
        self.current_goal = user_command
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """
        You are an AI Game Agent in 'Vision Safari'. 
        You see a grid with:
        - 'P' (Player, Blue Circle)
        - 'ğŸŒ²' (Obstacles, Trees)
        - Animals on colors (Targets)
        
        Goal: Navigate the Player to the target mentioned by the user.
        Rule: Avoid trees. Move step by step.
        """

        # ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬
        if "," in image_base64:
            image_base64 = image_base64.split(",")[1]

        # ë©”ì‹œì§€ êµ¬ì„± (Memory + Current Vision)
        messages = [
            SystemMessage(content=system_prompt),
            *self.memory.chat_memory.messages,
            HumanMessage(content=[
                {"type": "text", "text": f"Current Goal: {user_command}\nDecide your next move based on this screenshot."},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_base64}"}}
            ])
        ]

        # ëª¨ë¸ í˜¸ì¶œ
        response = await self.agent_with_tools.ainvoke(messages)
        
        # Tool Call ê²°ê³¼ í•´ì„
        if response.tool_calls:
            tool_call = response.tool_calls[0]
            action_name = tool_call["name"]
            args = tool_call["args"]
            
            # ë©”ëª¨ë¦¬ì— ì—ì´ì „íŠ¸ì˜ ê²°ì • ì €ì¥
            self.memory.chat_memory.add_user_message(f"Action taken: {action_name} with args {args}")
            self.memory.chat_memory.add_ai_message(f"Decision reason: {args.get('reason')}")
            
            return {"action": action_name.upper(), **args}
        
        return {"action": "IDLE", "reason": "No clear tool call generated."}

# --- ê¸€ë¡œë²Œ ì„¸ì…˜ ì €ì¥ì†Œ ---
agent_sessions: Dict[str, SafariAgentSession] = {}

async def handle_vision_safari(websocket: WebSocket, message: Dict[str, Any]):
    session_id = str(hash(websocket))
    if session_id not in agent_sessions:
        agent_sessions[session_id] = SafariAgentSession()
    
    agent = agent_sessions[session_id]
    event_type = message.get("event")

    if event_type == "USER_COMMAND":
        # ì‚¬ìš©ìê°€ ëª…ë ¹ì„ ë‚´ë¦¬ë©´ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ê³  ê´€ì°° ì‹œì‘
        user_payload = message.get("payload")
        agent.current_goal = user_payload
        agent.memory.chat_memory.add_user_message(f"New User Goal: {user_payload}")
        await websocket.send_text(json.dumps({"action": "CAPTURE_SCREEN"}))
        
    elif event_type == "SCREEN_DATA":
        image_data = message.get("image")
        
        # ì—ì´ì „íŠ¸ê°€ íŒë‹¨
        decision = await agent.decide_next_action(agent.current_goal, image_data)
        
        # í´ë¼ì´ì–¸íŠ¸ì— ëª…ë ¹ ì „ì†¡
        if decision["action"] == "MOVEACTION": # Pydantic í´ë˜ìŠ¤ëª…ì´ ì†Œë¬¸ìë¡œ ì˜¬ ìˆ˜ ìˆìŒ
            await websocket.send_text(json.dumps({
                "action": "MOVE",
                "direction": decision["direction"],
                "steps": decision.get("steps", 1)
            }))
        else:
            await websocket.send_text(json.dumps({"action": "IDLE", "reason": decision.get("reason")}))
        
    elif event_type == "MOVE_COMPLETE":
        # ì´ë™ì´ ì™„ë£Œë˜ë©´ ë©”ëª¨ë¦¬ì— ê²°ê³¼ ì—…ë°ì´íŠ¸
        pos = message.get("pos")
        agent.memory.chat_memory.add_user_message(f"Movement complete. Current position: {pos}")
        
        # ì—¬ê¸°ì„œ ìë™ìœ¼ë¡œ ë‹¤ìŒ CAPTURE_SCREENì„ ë³´ë‚´ë©´ "ì—°ì†ì ì¸ ì—ì´ì „íŠ¸ í–‰ë™"ì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.
        # print(f"[Vision Safari] Agent moved to {pos}, continuing goal...")
        # await websocket.send_text(json.dumps({"action": "CAPTURE_SCREEN"}))
