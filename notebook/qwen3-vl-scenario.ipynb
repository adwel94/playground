{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLM + Tool Calling ì ì§„ì  ê²€ì¦\n",
    "\n",
    "safari-sample.png ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì¸ì‹ â†’ ì¢Œí‘œ ì¶”ë¡  â†’ ë„êµ¬ í˜¸ì¶œ ìˆœì„œë¡œ ëŠ¥ë ¥ì„ ê²€ì¦í•œë‹¤.\n",
    "\n",
    "| ID | í…ŒìŠ¤íŠ¸ | ì¸¡ì • ëŠ¥ë ¥ | ì‘ë‹µ ë°©ì‹ ~~**|**~~\n",
    "|----|--------|---------|----------|\n",
    "| S1 | ì›ìˆ­ì´ ì¢Œí‘œ ì¸ì‹ | VLM ì¸ì‹ | í…ìŠ¤íŠ¸ |\n",
    "| S2 | ê¸°ë¦° ì¢Œí‘œ ì¸ì‹ | VLM ì¸ì‹ | í…ìŠ¤íŠ¸ |\n",
    "| S3 | ì›ìˆ­ì´ ì ‘ê·¼ ì´ë™ | VLM+ì¶”ë¡ +tool | move tool |\n",
    "| S4 | ê¸°ë¦° ì ‘ê·¼ ì´ë™ | VLM+ì¶”ë¡ +tool | move tool |\n",
    "| S5 | ì›ìˆ­ì´ í¬íš | VLM+ë³µí•©tool | move+catch |\n",
    "| S6 | ì¢…í•© ë¯¸ì…˜ | ì „ì²´ í†µí•© | move+catch+declare |\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T02:27:13.613934100Z",
     "start_time": "2026-02-25T02:27:13.443348600Z"
    }
   },
   "source": [
    "# â”€â”€ Cell 1: í™˜ê²½ ì„¤ì • + ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "print(\"í™˜ê²½ ì„¤ì • ë° ê²½ë¡œ ì¶”ê°€ ì™„ë£Œ\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™˜ê²½ ì„¤ì • ë° ê²½ë¡œ ì¶”ê°€ ì™„ë£Œ\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T02:30:04.157652800Z",
     "start_time": "2026-02-25T02:27:13.622348Z"
    }
   },
   "source": "# â”€â”€ Cell 2: LLM ì—°ê²° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import HumanMessage\n\nllm_configs = {\n    \"runpod\": {\n        \"base_url\": \"https://api.runpod.ai/v2/8iiebdj6zt0fbd/openai/v1\",\n        \"model\": \"qwen/qwen3-vl-4b-thinking-fp8\",\n        \"api_key\": os.getenv(\"RUNPOD_API_KEY\"),\n    },\n    \"local\": {\n        \"base_url\": \"http://192.168.50.32:8000/v1\",\n        \"model\": \"Qwen3-VL-2B-Thinking\",\n        \"api_key\": \"EMPTY\",\n    },\n    \"local-emoji\": {\n        \"base_url\": \"http://192.168.50.32:8000/v1\",\n        \"model\": \"emoji-lora\",\n        \"api_key\": \"EMPTY\",\n    },\n    \"local-safari\": {\n        \"base_url\": \"http://192.168.50.32:8000/v1\",\n        \"model\": \"safari-lora\",\n        \"api_key\": \"EMPTY\",\n    },\n}\n\n# â”€â”€ ì‚¬ìš©í•  ì„¤ì • ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntarget = \"local\"\ncfg = llm_configs[target]\n\nVLLM_BASE_URL = cfg[\"base_url\"]\nMODEL_NAME = cfg[\"model\"]\n\nprint(f\"í˜„ì¬ í™œì„±í™”ëœ ì„¤ì •: [{target}]\")\nprint(f\"Base URL: {VLLM_BASE_URL}\")\nprint(f\"Model Name: {MODEL_NAME}\")\n\nllm = ChatOpenAI(\n    base_url=VLLM_BASE_URL,\n    model=MODEL_NAME,\n    temperature=0,\n    api_key=cfg[\"api_key\"],\n    max_tokens=16000,\n)\n\nresponse = llm.invoke([HumanMessage(content=\"ì—°ê²° í…ŒìŠ¤íŠ¸. í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µí•´.\")])\nprint(f\"\\n[ì—°ê²° í™•ì¸] {response.content[:200]}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T02:30:04.366394100Z",
     "start_time": "2026-02-25T02:30:04.199867400Z"
    }
   },
   "source": [
    "# â”€â”€ Cell 3: ë„êµ¬ ì •ì˜ + í…ŒìŠ¤íŠ¸ í•˜ë„¤ìŠ¤ (ë©€í‹°í„´ ì§€ì›) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import json as _json\n",
    "import time as _time\n",
    "import re as _re\n",
    "import base64 as _base64\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage, AIMessage, ToolMessage, SystemMessage,\n",
    ")\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# â”€â”€ ë„êµ¬ ìŠ¤í‚¤ë§ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "class Action(BaseModel):\n",
    "    direction: Literal[\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"] = Field(\n",
    "        description=\"ì´ë™ ë°©í–¥\"\n",
    "    )\n",
    "    steps: int = Field(description=\"ì´ë™ ì¹¸ìˆ˜ (1~3)\", ge=1, le=3)\n",
    "\n",
    "class MoveArgs(BaseModel):\n",
    "    actions: list[Action] = Field(description=\"ìµœëŒ€ 4ê°œ í–‰ë™ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰\")\n",
    "\n",
    "@tool(args_schema=MoveArgs)\n",
    "def move(actions: list[Action]) -> str:\n",
    "    \"\"\"í”Œë ˆì´ì–´ë¥¼ ì´ë™ì‹œí‚¨ë‹¤.\"\"\"\n",
    "    return _json.dumps({\"moved\": True})\n",
    "\n",
    "class CatchArgs(BaseModel):\n",
    "    direction: Literal[\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"] = Field(\n",
    "        description=\"í¬íší•  ë™ë¬¼ì´ ìˆëŠ” ë°©í–¥\"\n",
    "    )\n",
    "\n",
    "@tool(args_schema=CatchArgs)\n",
    "def catch_animal(direction: str) -> str:\n",
    "    \"\"\"ì¸ì ‘ íƒ€ì¼(ìƒí•˜ì¢Œìš°)ì˜ ë™ë¬¼ì„ í¬íší•œë‹¤.\"\"\"\n",
    "    return _json.dumps({\"success\": True, \"animal\": {\"emoji\": \"\\ud83d\\udc12\"}})\n",
    "\n",
    "class NotepadArgs(BaseModel):\n",
    "    content: str = Field(\n",
    "        description=\"ë©”ëª¨ì¥ ì „ì²´ë¥¼ ë®ì–´ì“´ë‹¤. ìœ ì§€í•  ë‚´ìš©ë„ í¬í•¨í•´ì„œ ì‘ì„±í•´ì•¼ í•œë‹¤. ìµœëŒ€ 2000ì.\"\n",
    "    )\n",
    "\n",
    "@tool(args_schema=NotepadArgs)\n",
    "def update_notepad(content: str) -> str:\n",
    "    \"\"\"ë©”ëª¨ì¥ ì „ì²´ë¥¼ ë®ì–´ì“´ë‹¤.\"\"\"\n",
    "    return _json.dumps({\"status\": \"updated\"})\n",
    "\n",
    "class DeclareFoundArgs(BaseModel):\n",
    "    target: str = Field(description=\"ì°¾ì€ íƒ€ê²Ÿ ì´ë¦„\")\n",
    "\n",
    "@tool(args_schema=DeclareFoundArgs)\n",
    "def declare_found(target: str) -> str:\n",
    "    \"\"\"íŠ¹ì • íƒ€ê²Ÿì„ ì°¾ì•„ì„œ ë„ë‹¬í–ˆìŒì„ ì„ ì–¸í•œë‹¤.\"\"\"\n",
    "    return _json.dumps({\"declared\": True})\n",
    "\n",
    "class DeclareDoneArgs(BaseModel):\n",
    "    reason: str = Field(default=\"\", description=\"ë¯¸ì…˜ ì™„ë£Œ ì‚¬ìœ \")\n",
    "\n",
    "@tool(args_schema=DeclareDoneArgs)\n",
    "def declare_done(reason: str = \"\") -> str:\n",
    "    \"\"\"ì „ì²´ ë¯¸ì…˜ì´ ì™„ë£Œë˜ì—ˆìŒì„ ì„ ì–¸í•œë‹¤.\"\"\"\n",
    "    return _json.dumps({\"done\": True})\n",
    "\n",
    "ALL_TOOLS = [move, catch_animal, update_notepad, declare_found, declare_done]\n",
    "\n",
    "SYSTEM_MSG = (\n",
    "    \"ë„ˆëŠ” 50x50 ê²©ì ë§µ ìœ„ì˜ ì‚¬íŒŒë¦¬ ì—ì´ì „íŠ¸ì•¼.\\n\"\n",
    "    \"ì´ë¯¸ì§€ëŠ” ì „ì²´ ë§µì´ ì•„ë‹ˆë¼, ë„¤ ì£¼ë³€ 10x10 ì¹¸ë§Œ ë³´ì—¬ì£¼ëŠ” ë·°í¬íŠ¸ì´ë‹¤.\\n\"\n",
    "    \"ë„ˆ(P)ëŠ” ë·°í¬íŠ¸ì˜ ì™¼ìª½ì—ì„œ 5ë²ˆì§¸, ìœ„ì—ì„œ 5ë²ˆì§¸ ì¹¸ì— ìˆë‹¤.\\n\"\n",
    "    \"ë°˜ë“œì‹œ ì œê³µëœ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ í–‰ë™í•´. í…ìŠ¤íŠ¸ë¡œ ë‹µí•˜ì§€ ë§ê³  ë„êµ¬ë¥¼ í˜¸ì¶œí•´.\\n\"\n",
    "    \"ì¢Œí‘œê³„: xì¶•ì€ RIGHT(+)/LEFT(-), yì¶•ì€ DOWN(+)/UP(-).\"\n",
    ")\n",
    "\n",
    "# â”€â”€ args listâ†’dict ìë™ ë³´ì • fallback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def _to_openai_messages(messages):\n",
    "    \"\"\"langchain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ OpenAI API í˜•ì‹ìœ¼ë¡œ ë³€í™˜.\"\"\"\n",
    "    result = []\n",
    "    for m in messages:\n",
    "        if isinstance(m, SystemMessage):\n",
    "            result.append({\"role\": \"system\", \"content\": m.content})\n",
    "        elif isinstance(m, HumanMessage):\n",
    "            result.append({\"role\": \"user\", \"content\": m.content})\n",
    "        elif isinstance(m, AIMessage):\n",
    "            msg = {\"role\": \"assistant\", \"content\": m.content or \"\"}\n",
    "            if m.tool_calls:\n",
    "                msg[\"tool_calls\"] = [\n",
    "                    {\n",
    "                        \"id\": tc[\"id\"],\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": tc[\"name\"],\n",
    "                            \"arguments\": _json.dumps(tc[\"args\"]),\n",
    "                        },\n",
    "                    }\n",
    "                    for tc in m.tool_calls\n",
    "                ]\n",
    "            result.append(msg)\n",
    "        elif isinstance(m, ToolMessage):\n",
    "            result.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": m.content,\n",
    "                \"tool_call_id\": m.tool_call_id,\n",
    "            })\n",
    "    return result\n",
    "\n",
    "\n",
    "def _fix_tool_call_args(raw_tool_calls):\n",
    "    \"\"\"\n",
    "    raw OpenAI tool_callsì—ì„œ argsê°€ listì¸ ê²½ìš° {\"actions\": list}ë¡œ ë˜í•‘.\n",
    "    ëª¨ë¸ì´ ê°„í—ì ìœ¼ë¡œ wrapper dictë¥¼ ìƒëµí•˜ëŠ” ë¹„ê²°ì •ì  í¬ë§· ì˜¤ë¥˜ë¥¼ ë³´ì •í•œë‹¤.\n",
    "    \"\"\"\n",
    "    fixed = []\n",
    "    for tc in raw_tool_calls:\n",
    "        args = _json.loads(tc.function.arguments)\n",
    "        if isinstance(args, list):\n",
    "            args = {\"actions\": args}\n",
    "            print(f\"  [ë³´ì •] {tc.function.name}: args list â†’ {{\\\"actions\\\": [...]}} ë˜í•‘\")\n",
    "        fixed.append({\n",
    "            \"name\": tc.function.name,\n",
    "            \"args\": args,\n",
    "            \"id\": tc.id,\n",
    "            \"type\": \"tool_call\",\n",
    "        })\n",
    "    return fixed\n",
    "\n",
    "\n",
    "class _FallbackResponse:\n",
    "    \"\"\"pydantic ê²€ì¦ ì‹¤íŒ¨ ì‹œ raw OpenAI ì‘ë‹µì„ langchain í˜¸í™˜ í˜•íƒœë¡œ ê°ì‹¸ëŠ” ë˜í¼.\"\"\"\n",
    "    def __init__(self, content, tool_calls, response_metadata):\n",
    "        self.content = content\n",
    "        self.tool_calls = tool_calls\n",
    "        self.response_metadata = response_metadata\n",
    "\n",
    "\n",
    "def _invoke_with_tool_fallback(llm_instance, tools, messages):\n",
    "    \"\"\"\n",
    "    bind_tools ê¸°ë°˜ í˜¸ì¶œ í›„, argsê°€ listë¡œ ë°˜í™˜ë˜ì–´ pydantic ê²€ì¦ ì‹¤íŒ¨í•˜ë©´\n",
    "    raw OpenAI clientë¡œ ì¬í˜¸ì¶œí•˜ì—¬ argsë¥¼ dictë¡œ ìë™ ë˜í•‘í•œë‹¤.\n",
    "    \"\"\"\n",
    "    llm_with_tools = llm_instance.bind_tools(tools)\n",
    "    try:\n",
    "        return llm_with_tools.invoke(messages)\n",
    "    except Exception as e:\n",
    "        err_str = str(e)\n",
    "        if \"input_type=list\" not in err_str or \"dict_type\" not in err_str:\n",
    "            raise\n",
    "\n",
    "    # â”€â”€ Fallback: raw OpenAI client ì¬í˜¸ì¶œ â”€â”€\n",
    "    print(\"  [ë³´ì •] pydantic validation error ê°ì§€ â†’ raw client fallback\")\n",
    "    openai_tools = [convert_to_openai_tool(t) for t in tools]\n",
    "    openai_msgs = _to_openai_messages(messages)\n",
    "\n",
    "    raw_resp = llm_instance.client.create(\n",
    "        model=llm_instance.model_name,\n",
    "        messages=openai_msgs,\n",
    "        tools=openai_tools,\n",
    "        temperature=0,\n",
    "        max_tokens=llm_instance.max_tokens,\n",
    "    )\n",
    "\n",
    "    choice = raw_resp.choices[0]\n",
    "    msg = choice.message\n",
    "\n",
    "    tool_calls = _fix_tool_call_args(msg.tool_calls) if msg.tool_calls else []\n",
    "    usage = raw_resp.usage\n",
    "\n",
    "    return _FallbackResponse(\n",
    "        content=msg.content or \"\",\n",
    "        tool_calls=tool_calls,\n",
    "        response_metadata={\n",
    "            \"token_usage\": {\n",
    "                \"prompt_tokens\": usage.prompt_tokens if usage else 0,\n",
    "                \"completion_tokens\": usage.completion_tokens if usage else 0,\n",
    "                \"total_tokens\": usage.total_tokens if usage else 0,\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "# â”€â”€ ê³µí†µ: ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶œë ¥ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def _print_response_text(resp, passed):\n",
    "    \"\"\"ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶œë ¥. ì‹¤íŒ¨ ì‹œ ì „ì²´ í…ìŠ¤íŠ¸, ì„±ê³µ ì‹œ 200ì ìš”ì•½.\"\"\"\n",
    "    if not resp.content:\n",
    "        return\n",
    "    content = resp.content\n",
    "    if \"</think>\" in content:\n",
    "        content = content.split(\"</think>\")[-1].strip()\n",
    "    if not content:\n",
    "        return\n",
    "    if passed:\n",
    "        print(f\"  ì‘ë‹µ í…ìŠ¤íŠ¸: {content[:200]}\")\n",
    "    else:\n",
    "        print(f\"  ì‘ë‹µ í…ìŠ¤íŠ¸ (ì „ì²´ â€” tool call ì‹¤íŒ¨ ì‹œ ëª¨ë¸ ì¶œë ¥):\")\n",
    "        for line in content.splitlines():\n",
    "            print(f\"    {line}\")\n",
    "\n",
    "# â”€â”€ ì¢Œí‘œ ì¶”ì¶œ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def extract_coordinates(text):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ì—ì„œ (x, y) ì¢Œí‘œë¥¼ ì¶”ì¶œí•œë‹¤. </think> íƒœê·¸ ì´í›„ë§Œ íŒŒì‹±.\"\"\"\n",
    "    if \"</think>\" in text:\n",
    "        text = text.split(\"</think>\")[-1]\n",
    "    return [(int(x), int(y)) for x, y in _re.findall(r'\\((\\d+)\\s*,\\s*(\\d+)\\)', text)]\n",
    "\n",
    "# â”€â”€ VLM í…ìŠ¤íŠ¸ ì‘ë‹µ í…ŒìŠ¤íŠ¸ í•˜ë„¤ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def run_vlm_test(\n",
    "    test_id: str,\n",
    "    title: str,\n",
    "    messages: list,\n",
    "    validator=None,\n",
    "    llm_override=None,\n",
    ") -> dict:\n",
    "    \"\"\"ë„êµ¬ ì—†ì´ í…ìŠ¤íŠ¸ ì‘ë‹µë§Œ ë°›ëŠ” VLM í…ŒìŠ¤íŠ¸ í•˜ë„¤ìŠ¤.\"\"\"\n",
    "    llm_instance = llm_override or llm\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {test_id}: {title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    start = _time.time()\n",
    "    try:\n",
    "        resp = llm_instance.invoke(messages)\n",
    "        elapsed = _time.time() - start\n",
    "    except Exception as e:\n",
    "        elapsed = _time.time() - start\n",
    "        print(f\"\\n  FAIL - í˜¸ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "        return {\n",
    "            \"id\": test_id, \"title\": title, \"passed\": False,\n",
    "            \"reason\": str(e), \"tool_calls\": [], \"tokens\": {}, \"elapsed\": elapsed,\n",
    "        }\n",
    "\n",
    "    usage = resp.response_metadata.get(\"token_usage\", {})\n",
    "    tokens = {\n",
    "        \"prompt\": usage.get(\"prompt_tokens\", \"?\"),\n",
    "        \"completion\": usage.get(\"completion_tokens\", \"?\"),\n",
    "        \"total\": usage.get(\"total_tokens\", \"?\"),\n",
    "    }\n",
    "\n",
    "    if validator:\n",
    "        passed, reason = validator(resp)\n",
    "    else:\n",
    "        passed = bool(resp.content and resp.content.strip())\n",
    "        reason = \"í…ìŠ¤íŠ¸ ì‘ë‹µ ì¡´ì¬\" if passed else \"ì‘ë‹µ ì—†ìŒ\"\n",
    "\n",
    "    status = \"PASS\" if passed else \"FAIL\"\n",
    "\n",
    "    print(f\"\\n  ìƒíƒœ: {status}\")\n",
    "    print(f\"  ì‚¬ìœ : {reason}\")\n",
    "    print(f\"  ì†Œìš”ì‹œê°„: {elapsed:.1f}s\")\n",
    "    print(f\"  í† í°: prompt={tokens['prompt']}, completion={tokens['completion']}, total={tokens['total']}\")\n",
    "\n",
    "    _print_response_text(resp, passed)\n",
    "\n",
    "    return {\n",
    "        \"id\": test_id, \"title\": title, \"passed\": passed,\n",
    "        \"reason\": reason, \"tool_calls\": [],\n",
    "        \"tokens\": tokens, \"elapsed\": elapsed,\n",
    "    }\n",
    "\n",
    "# â”€â”€ ì‹±ê¸€í„´ í…ŒìŠ¤íŠ¸ í•˜ë„¤ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def run_test(\n",
    "    test_id: str,\n",
    "    title: str,\n",
    "    messages: list,\n",
    "    tools: list = None,\n",
    "    validator=None,\n",
    "    llm_override=None,\n",
    ") -> dict:\n",
    "    \"\"\"ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥. llm_overrideë¡œ ë³„ë„ LLM ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© ê°€ëŠ¥.\"\"\"\n",
    "    if tools is None:\n",
    "        tools = ALL_TOOLS\n",
    "    llm_instance = llm_override or llm\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {test_id}: {title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    start = _time.time()\n",
    "    try:\n",
    "        resp = _invoke_with_tool_fallback(llm_instance, tools, messages)\n",
    "        elapsed = _time.time() - start\n",
    "    except Exception as e:\n",
    "        elapsed = _time.time() - start\n",
    "        print(f\"\\n  FAIL - í˜¸ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "        return {\n",
    "            \"id\": test_id, \"title\": title, \"passed\": False,\n",
    "            \"reason\": str(e), \"tool_calls\": [], \"tokens\": {}, \"elapsed\": elapsed,\n",
    "        }\n",
    "\n",
    "    usage = resp.response_metadata.get(\"token_usage\", {})\n",
    "    tokens = {\n",
    "        \"prompt\": usage.get(\"prompt_tokens\", \"?\"),\n",
    "        \"completion\": usage.get(\"completion_tokens\", \"?\"),\n",
    "        \"total\": usage.get(\"total_tokens\", \"?\"),\n",
    "    }\n",
    "\n",
    "    tool_calls = resp.tool_calls or []\n",
    "\n",
    "    if validator:\n",
    "        passed, reason = validator(resp, tool_calls)\n",
    "    else:\n",
    "        passed = len(tool_calls) > 0\n",
    "        reason = \"tool call ì¡´ì¬\" if passed else \"tool call ì—†ìŒ\"\n",
    "\n",
    "    status = \"PASS\" if passed else \"FAIL\"\n",
    "\n",
    "    print(f\"\\n  ìƒíƒœ: {status}\")\n",
    "    print(f\"  ì‚¬ìœ : {reason}\")\n",
    "    print(f\"  ì†Œìš”ì‹œê°„: {elapsed:.1f}s\")\n",
    "    print(f\"  í† í°: prompt={tokens['prompt']}, completion={tokens['completion']}, total={tokens['total']}\")\n",
    "    print(f\"  Tool calls ({len(tool_calls)}ê°œ):\")\n",
    "    for i, tc in enumerate(tool_calls):\n",
    "        print(f\"    [{i}] {tc['name']}({_json.dumps(tc['args'], ensure_ascii=False)})\")\n",
    "\n",
    "    _print_response_text(resp, passed)\n",
    "\n",
    "    return {\n",
    "        \"id\": test_id, \"title\": title, \"passed\": passed,\n",
    "        \"reason\": reason, \"tool_calls\": tool_calls,\n",
    "        \"tokens\": tokens, \"elapsed\": elapsed,\n",
    "    }\n",
    "\n",
    "# â”€â”€ ë©€í‹°í„´ í…ŒìŠ¤íŠ¸ í•˜ë„¤ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def run_multiturn_test(\n",
    "    test_id: str,\n",
    "    title: str,\n",
    "    turns: list[dict],\n",
    "    tools: list = None,\n",
    "    validator=None,\n",
    "    llm_override=None,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    ë©€í‹°í„´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰.\n",
    "    turns: list of {\"user_msg\": str, \"tool_results\": dict[tool_name, str]}\n",
    "      - user_msg: í•´ë‹¹ í„´ì˜ ì‚¬ìš©ì ë©”ì‹œì§€ (ì²« í„´ì€ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìë™ í¬í•¨)\n",
    "      - tool_results: ì´ì „ í„´ì˜ tool callì— ëŒ€í•œ ëª¨ì˜ ê²°ê³¼ (ì²« í„´ì€ ë¬´ì‹œ)\n",
    "    validator: (all_turn_tool_calls: list[list[dict]], messages) -> (bool, str)\n",
    "    \"\"\"\n",
    "    if tools is None:\n",
    "        tools = ALL_TOOLS\n",
    "    llm_instance = llm_override or llm\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {test_id}: {title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    messages = [SystemMessage(content=SYSTEM_MSG)]\n",
    "\n",
    "    all_turn_tool_calls = []\n",
    "    all_turn_responses = []\n",
    "    total_tokens = {\"prompt\": 0, \"completion\": 0, \"total\": 0}\n",
    "    start = _time.time()\n",
    "\n",
    "    for turn_idx, turn in enumerate(turns):\n",
    "        print(f\"\\n  -- Turn {turn_idx + 1} --\")\n",
    "\n",
    "        # ì´ì „ í„´ì˜ tool result ì¶”ê°€ (turn_idx > 0)\n",
    "        if turn_idx > 0 and all_turn_tool_calls[turn_idx - 1]:\n",
    "            prev_tc = all_turn_tool_calls[turn_idx - 1]\n",
    "            tool_result_map = turn.get(\"tool_results\", {})\n",
    "            for tc in prev_tc:\n",
    "                result_content = tool_result_map.get(\n",
    "                    tc[\"name\"],\n",
    "                    _json.dumps({\"ok\": True}),\n",
    "                )\n",
    "                messages.append(ToolMessage(\n",
    "                    content=result_content,\n",
    "                    tool_call_id=tc[\"id\"],\n",
    "                ))\n",
    "\n",
    "        messages.append(HumanMessage(content=turn[\"user_msg\"]))\n",
    "\n",
    "        try:\n",
    "            resp = _invoke_with_tool_fallback(llm_instance, tools, messages)\n",
    "        except Exception as e:\n",
    "            print(f\"    FAIL - í˜¸ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "            all_turn_tool_calls.append([])\n",
    "            all_turn_responses.append(None)\n",
    "            messages.append(AIMessage(content=str(e)))\n",
    "            continue\n",
    "\n",
    "        usage = resp.response_metadata.get(\"token_usage\", {})\n",
    "        for k in total_tokens:\n",
    "            key = f\"{k}_tokens\"\n",
    "            total_tokens[k] += usage.get(key, 0)\n",
    "\n",
    "        tc = resp.tool_calls or []\n",
    "        all_turn_tool_calls.append(tc)\n",
    "        all_turn_responses.append(resp)\n",
    "\n",
    "        # _FallbackResponseëŠ” AIMessageê°€ ì•„ë‹ˆë¯€ë¡œ messagesì— AIMessageë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€\n",
    "        if isinstance(resp, _FallbackResponse):\n",
    "            ai_msg = AIMessage(content=resp.content)\n",
    "            # tool_callsëŠ” pydantic ê²€ì¦ ìš°íšŒ ìœ„í•´ additional_kwargsì—ë§Œ ì €ì¥\n",
    "            ai_msg.additional_kwargs[\"tool_calls\"] = [\n",
    "                {\n",
    "                    \"id\": t[\"id\"],\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": t[\"name\"],\n",
    "                        \"arguments\": _json.dumps(t[\"args\"]),\n",
    "                    },\n",
    "                }\n",
    "                for t in tc\n",
    "            ]\n",
    "            messages.append(ai_msg)\n",
    "        else:\n",
    "            messages.append(resp)\n",
    "\n",
    "        for i, t in enumerate(tc):\n",
    "            print(f\"    [{i}] {t['name']}({_json.dumps(t['args'], ensure_ascii=False)})\")\n",
    "        if not tc:\n",
    "            print(f\"    (tool call ì—†ìŒ)\")\n",
    "            # ì‹¤íŒ¨í•œ í„´ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸ ì „ì²´ ì¶œë ¥\n",
    "            _print_response_text(resp, False)\n",
    "\n",
    "    elapsed = _time.time() - start\n",
    "\n",
    "    if validator:\n",
    "        passed, reason = validator(all_turn_tool_calls, messages)\n",
    "    else:\n",
    "        passed = all(len(tc) > 0 for tc in all_turn_tool_calls)\n",
    "        reason = \"ëª¨ë“  í„´ tool call ì¡´ì¬\" if passed else \"ì¼ë¶€ í„´ tool call ì—†ìŒ\"\n",
    "\n",
    "    status = \"PASS\" if passed else \"FAIL\"\n",
    "    print(f\"\\n  ìƒíƒœ: {status}\")\n",
    "    print(f\"  ì‚¬ìœ : {reason}\")\n",
    "    print(f\"  ì†Œìš”ì‹œê°„: {elapsed:.1f}s\")\n",
    "    print(f\"  ëˆ„ì  í† í°: {total_tokens}\")\n",
    "\n",
    "    flat_calls = [tc for turn_tc in all_turn_tool_calls for tc in turn_tc]\n",
    "    return {\n",
    "        \"id\": test_id, \"title\": title, \"passed\": passed,\n",
    "        \"reason\": reason, \"tool_calls\": flat_calls,\n",
    "        \"turn_tool_calls\": all_turn_tool_calls,\n",
    "        \"tokens\": total_tokens, \"elapsed\": elapsed,\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"í…ŒìŠ¤íŠ¸ í•˜ë„¤ìŠ¤ ë° ë„êµ¬ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"ì‚¬ìš© ê°€ëŠ¥ ë„êµ¬: {[t.name for t in ALL_TOOLS]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸ í•˜ë„¤ìŠ¤ ë° ë„êµ¬ ì •ì˜ ì™„ë£Œ\n",
      "ì‚¬ìš© ê°€ëŠ¥ ë„êµ¬: ['move', 'catch_animal', 'update_notepad', 'declare_found', 'declare_done']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í…ŒìŠ¤íŠ¸ ì•„í‚¤í…ì²˜\n",
    "\n",
    "**ì´ë¯¸ì§€ ê¸°ë°˜ ì ì§„ì  ê²€ì¦:** safari-sample.png (10x10 ë·°í¬íŠ¸) í•˜ë‚˜ë¡œ ëª¨ë“  í…ŒìŠ¤íŠ¸ ìˆ˜í–‰.\n",
    "\n",
    "**ë‹¨ê³„:**\n",
    "1. **ì¸ì‹** (S1-S2): ì´ë¯¸ì§€ì—ì„œ ë™ë¬¼ ì¢Œí‘œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë‹µë³€ â€” VLM perception ê²€ì¦\n",
    "2. **ì¶”ë¡ +ë„êµ¬** (S3-S4): ì¢Œí‘œ ì°¨ì´ ê³„ì‚° í›„ move ë„êµ¬ í˜¸ì¶œ â€” ì¶”ë¡ +tool ê²€ì¦\n",
    "3. **ë³µí•© ë„êµ¬** (S5): ì´ë™ + í¬íš â€” multi-tool ê²€ì¦\n",
    "4. **í†µí•©** (S6): ì´ë™ + í¬íš + ì„ ì–¸ + ë©”ëª¨ â€” full workflow ê²€ì¦\n",
    "\n",
    "**ì¢Œí‘œê³„:** `UP=y-1, DOWN=y+1, RIGHT=x+1, LEFT=x-1` (ì‹¤ì œ ê²Œì„ê³¼ í†µì¼)\n",
    "\n",
    "**Ground Truth:** Player(25,25), Monkey(29,23), Giraffe(29,28) â€” í—ˆìš© ì˜¤ì°¨ Â±2\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T02:30:04.406455200Z",
     "start_time": "2026-02-25T02:30:04.370388800Z"
    }
   },
   "source": [
    "# â”€â”€ Cell 5: ì´ë¯¸ì§€ ë¡œë“œ + Ground Truth ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¡œë“œ\n",
    "sample_img_path = \"images/safari-sample.png\"\n",
    "with open(sample_img_path, \"rb\") as f:\n",
    "    _b64 = _base64.b64encode(f.read()).decode()\n",
    "IMAGE_URL = f\"data:image/png;base64,{_b64}\"\n",
    "\n",
    "# Ground Truth\n",
    "PLAYER_POS = (25, 25)\n",
    "MONKEY_POS = (29, 23)   # ë¹¨ê°„ë°°ê²½, ë·°í¬íŠ¸(8,2)\n",
    "GIRAFFE_POS = (29, 28)  # ë…¸ë€ë°°ê²½, ë·°í¬íŠ¸(8,7)\n",
    "COORD_TOLERANCE = 2     # ì¢Œí‘œ í—ˆìš© ì˜¤ì°¨\n",
    "\n",
    "# VLM ì¸ì‹ í…ŒìŠ¤íŠ¸ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë„êµ¬ í˜¸ì¶œ ì§€ì‹œ ì—†ìŒ)\n",
    "VLM_SYSTEM_MSG = (\n",
    "    \"ë„ˆëŠ” 50x50 ê²©ì ë§µì˜ ì‹œì•¼ ë¶„ì„ê°€ì•¼.\\n\"\n",
    "    \"ì´ ì´ë¯¸ì§€ëŠ” ì „ì²´ ë§µì´ ì•„ë‹ˆë¼, í”Œë ˆì´ì–´ ì£¼ë³€ 10x10 ì¹¸ë§Œ ë³´ì—¬ì£¼ëŠ” ë·°í¬íŠ¸ì´ë‹¤.\\n\"\n",
    "    \"ë·°í¬íŠ¸ëŠ” 10ì—´(ê°€ë¡œ) Ã— 10í–‰(ì„¸ë¡œ)ì˜ ê²©ìì´ë‹¤.\\n\"\n",
    "    \"í”Œë ˆì´ì–´(P)ëŠ” ë·°í¬íŠ¸ì—ì„œ ì™¼ìª½ì—ì„œ 5ë²ˆì§¸, ìœ„ì—ì„œ 5ë²ˆì§¸ ì¹¸ì— ìˆë‹¤.\\n\"\n",
    "    \"ì¢Œí‘œ ë³€í™˜ë²•: ë·°í¬íŠ¸ì—ì„œ P ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¸Œì íŠ¸ê°€ ì˜¤ë¥¸ìª½ìœ¼ë¡œ nì¹¸ì´ë©´ xì¢Œí‘œëŠ” í”Œë ˆì´ì–´x + n, ì•„ë˜ë¡œ mì¹¸ì´ë©´ yì¢Œí‘œëŠ” í”Œë ˆì´ì–´y + mì´ë‹¤.\\n\"\n",
    "    \"ì¢Œí‘œê³„: xì¶•ì€ RIGHT(+)/LEFT(-), yì¶•ì€ DOWN(+)/UP(-).\"\n",
    ")\n",
    "\n",
    "# ë„êµ¬ í˜¸ì¶œ í…ŒìŠ¤íŠ¸ìš© ê²Œì„ ì»¨í…ìŠ¤íŠ¸ í…œí”Œë¦¿\n",
    "def make_game_context(mission, step=1, max_steps=10):\n",
    "    return (\n",
    "        f\"Mission: {mission}\\n\"\n",
    "        f\"Step: {step}/{max_steps}\\n\"\n",
    "        f\"Position: ({PLAYER_POS[0]}, {PLAYER_POS[1]})\\n\"\n",
    "        \"Found Targets: (none)\\n\"\n",
    "        \"Notepad: (empty)\\n\"\n",
    "    )\n",
    "\n",
    "print(f\"ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {sample_img_path} ({len(_b64)} bytes base64)\")\n",
    "print(f\"Ground Truth: Player={PLAYER_POS}, Monkey={MONKEY_POS}, Giraffe={GIRAFFE_POS}\")\n",
    "print(f\"í—ˆìš© ì˜¤ì°¨: Â±{COORD_TOLERANCE}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: images/safari-sample.png (38864 bytes base64)\n",
      "Ground Truth: Player=(25, 25), Monkey=(29, 23), Giraffe=(29, 28)\n",
      "í—ˆìš© ì˜¤ì°¨: Â±2\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": "## ê¸°ì´ˆ ì‹œê° ì¸ì‹ ì§„ë‹¨ (Pre-S1)\n\nì¢Œí‘œ ì¶”ì¶œÂ·tool calling ì´ì „ì—, ëª¨ë¸ì´ ì´ë¯¸ì§€ë¥¼ **ë³¼ ìˆ˜ ìˆëŠ”ì§€** ìì²´ë¥¼ ë¨¼ì € ê²€ì¦í•œë‹¤.\në„êµ¬ ì—†ì´ í…ìŠ¤íŠ¸ ì‘ë‹µë§Œ ë°›ìœ¼ë©°, `max_tokens=2000`ìœ¼ë¡œ ì œí•œí•˜ì—¬ thinking ë£¨í”„ë¥¼ ë°©ì§€í•œë‹¤.\n\n| ID | ì§ˆë¬¸ | í†µê³¼ ê¸°ì¤€ |\n|----|------|----------|\n| Q1 | ì•„ì´ì½˜/ì´ëª¨ì§€ ë‚˜ì—´ | ì›ìˆ­ì´Â·ê¸°ë¦°Â·ë‚˜ë¬´Â·P ì¤‘ í•˜ë‚˜ ì´ìƒ ì–¸ê¸‰ |\n| Q2 | P ê¸°ì¤€ ë¹¨ê°„ ë°°ê²½ ë°©í–¥ | \"ìš°ìƒ\" ë˜ëŠ” \"ì˜¤ë¥¸ìª½ ìœ„\" ê³„ì—´ |\n| Q3 | P ê¸°ì¤€ ë…¸ë€ ë°°ê²½ ë°©í–¥ | \"ìš°í•˜\" ë˜ëŠ” \"ì˜¤ë¥¸ìª½ ì•„ë˜\" ê³„ì—´ |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# â”€â”€ ê¸°ì´ˆ ì‹œê° ì¸ì‹ ì§„ë‹¨ (Q1~Q3) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# ë„êµ¬ ì—†ì´ í…ìŠ¤íŠ¸ ì‘ë‹µë§Œ ë°›ì•„ ëª¨ë¸ì˜ ì‹œê° ì¸ì‹ ëŠ¥ë ¥ ìì²´ë¥¼ ê²€ì¦í•œë‹¤.\n# max_tokens=2000 ìœ¼ë¡œ thinking ë£¨í”„ ë°©ì§€.\n\nimport re as _re\n\ndiag_llm = ChatOpenAI(\n    base_url=VLLM_BASE_URL,\n    model=MODEL_NAME,\n    temperature=0,\n    api_key=cfg[\"api_key\"],\n    max_tokens=2000,\n)\n\ndiag_results = []\n\n# â”€â”€ Q1: ì•„ì´ì½˜ ë‚˜ì—´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\ndef validate_q1(resp):\n    text = resp.content\n    if \"</think>\" in text:\n        text = text.split(\"</think>\")[-1]\n    text_lower = text.lower()\n    keywords = [\"ì›ìˆ­ì´\", \"monkey\", \"ğŸ’\", \"ğŸµ\",\n                 \"ê¸°ë¦°\", \"giraffe\", \"ğŸ¦’\",\n                 \"ë‚˜ë¬´\", \"tree\", \"ğŸŒ²\", \"ğŸŒ³\", \"ğŸŒ´\",\n                 \"p\", \"í”Œë ˆì´ì–´\", \"player\"]\n    found = [k for k in keywords if k in text_lower]\n    if found:\n        return True, f\"ì‹œê° ì¸ì‹ ì‘ë™ â€” ì–¸ê¸‰ëœ í‚¤ì›Œë“œ: {found}\"\n    return False, \"ì•„ì´ì½˜/ì´ëª¨ì§€ ê´€ë ¨ í‚¤ì›Œë“œ ì—†ìŒ\"\n\nr = run_vlm_test(\n    test_id=\"Q1\",\n    title=\"ì•„ì´ì½˜ ë‚˜ì—´ (ì‹œê° ì¸ì‹ ê¸°ì´ˆ)\",\n    messages=[\n        HumanMessage(content=[\n            {\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_URL}},\n            {\"type\": \"text\", \"text\": \"ì´ ì´ë¯¸ì§€ì— ì–´ë–¤ ì•„ì´ì½˜/ì´ëª¨ì§€ê°€ ë³´ì´ëŠ”ì§€ ë‚˜ì—´í•´.\"},\n        ]),\n    ],\n    validator=validate_q1,\n    llm_override=diag_llm,\n)\ndiag_results.append(r)\n\n# â”€â”€ Q2: ë¹¨ê°„ ë°°ê²½ ë°©í–¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\ndef validate_q2(resp):\n    text = resp.content\n    if \"</think>\" in text:\n        text = text.split(\"</think>\")[-1]\n    # \"ìš°ìƒ\", \"ì˜¤ë¥¸ìª½ ìœ„\", \"right-up\", \"upper right\" ë“±\n    patterns = [\n        r\"ìš°ìƒ\", r\"ì˜¤ë¥¸ìª½\\s*ìœ„\", r\"ìš°ì¸¡\\s*ìƒ\", r\"ìƒ\\s*ìš°\",\n        r\"ìœ„\\s*ì˜¤ë¥¸\", r\"upper\\s*right\", r\"right\\s*up\",\n        r\"top\\s*right\", r\"right.*top\", r\"up.*right\",\n    ]\n    for p in patterns:\n        if _re.search(p, text, _re.IGNORECASE):\n            return True, f\"ì •í™• â€” '{p}' íŒ¨í„´ ë§¤ì¹˜\"\n    return False, f\"'ìš°ìƒ/ì˜¤ë¥¸ìª½ ìœ„' ê³„ì—´ ë‹µë³€ ì—†ìŒ\"\n\nr = run_vlm_test(\n    test_id=\"Q2\",\n    title=\"ë¹¨ê°„ ë°°ê²½ ë°©í–¥ (P ê¸°ì¤€)\",\n    messages=[\n        HumanMessage(content=[\n            {\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_URL}},\n            {\"type\": \"text\", \"text\": (\n                \"ì´ë¯¸ì§€ì—ì„œ P ê¸€ìê°€ ë³´ì¼ ê±°ì•¼. \"\n                \"P ê¸°ì¤€ìœ¼ë¡œ ë¹¨ê°„ìƒ‰ ë°°ê²½ì€ ì–´ëŠ ë°©í–¥ì— ìˆì–´? \"\n                \"(ìƒ/í•˜/ì¢Œ/ìš°/ìš°ìƒ/ìš°í•˜/ì¢Œìƒ/ì¢Œí•˜ ì¤‘ í•˜ë‚˜ë¡œ ë‹µí•´)\"\n            )},\n        ]),\n    ],\n    validator=validate_q2,\n    llm_override=diag_llm,\n)\ndiag_results.append(r)\n\n# â”€â”€ Q3: ë…¸ë€ ë°°ê²½ ë°©í–¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\ndef validate_q3(resp):\n    text = resp.content\n    if \"</think>\" in text:\n        text = text.split(\"</think>\")[-1]\n    # \"ìš°í•˜\", \"ì˜¤ë¥¸ìª½ ì•„ë˜\", \"right-down\", \"lower right\" ë“±\n    patterns = [\n        r\"ìš°í•˜\", r\"ì˜¤ë¥¸ìª½\\s*ì•„ë˜\", r\"ìš°ì¸¡\\s*í•˜\", r\"í•˜\\s*ìš°\",\n        r\"ì•„ë˜\\s*ì˜¤ë¥¸\", r\"lower\\s*right\", r\"right\\s*down\",\n        r\"bottom\\s*right\", r\"right.*bottom\", r\"down.*right\",\n    ]\n    for p in patterns:\n        if _re.search(p, text, _re.IGNORECASE):\n            return True, f\"ì •í™• â€” '{p}' íŒ¨í„´ ë§¤ì¹˜\"\n    return False, f\"'ìš°í•˜/ì˜¤ë¥¸ìª½ ì•„ë˜' ê³„ì—´ ë‹µë³€ ì—†ìŒ\"\n\nr = run_vlm_test(\n    test_id=\"Q3\",\n    title=\"ë…¸ë€ ë°°ê²½ ë°©í–¥ (P ê¸°ì¤€)\",\n    messages=[\n        HumanMessage(content=[\n            {\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_URL}},\n            {\"type\": \"text\", \"text\": (\n                \"ì´ë¯¸ì§€ì—ì„œ P ê¸€ìê°€ ë³´ì¼ ê±°ì•¼. \"\n                \"P ê¸°ì¤€ìœ¼ë¡œ ë…¸ë€ìƒ‰ ë°°ê²½ì€ ì–´ëŠ ë°©í–¥ì— ìˆì–´? \"\n                \"(ìƒ/í•˜/ì¢Œ/ìš°/ìš°ìƒ/ìš°í•˜/ì¢Œìƒ/ì¢Œí•˜ ì¤‘ í•˜ë‚˜ë¡œ ë‹µí•´)\"\n            )},\n        ]),\n    ],\n    validator=validate_q3,\n    llm_override=diag_llm,\n)\ndiag_results.append(r)\n\n# â”€â”€ ì§„ë‹¨ ê²°ê³¼ ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nprint(f\"\\n{'='*60}\")\nprint(f\"  ê¸°ì´ˆ ì‹œê° ì¸ì‹ ì§„ë‹¨ ê²°ê³¼\")\nprint(f\"{'='*60}\")\n\nfor r in diag_results:\n    status = \"PASS âœ“\" if r[\"passed\"] else \"FAIL âœ—\"\n    print(f\"  {r['id']}: {r['title']} â†’ {status}\")\n    print(f\"       {r['reason']}\")\n\npassed = sum(1 for r in diag_results if r[\"passed\"])\nprint(f\"\\n  ì§„ë‹¨ í†µê³¼: {passed}/{len(diag_results)}\")\n\nif passed == 0:\n    print(\"\\n  âš  ëª¨ë¸ì´ ì´ë¯¸ì§€ë¥¼ ì „í˜€ ì¸ì‹í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ì¢Œí‘œ/ë„êµ¬ í…ŒìŠ¤íŠ¸ ì§„í–‰ ë¶ˆí•„ìš”.\")\nelif passed < len(diag_results):\n    print(\"\\n  âš  ë¶€ë¶„ì  ì¸ì‹. S1 ì´í›„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í•´ì„ ì‹œ ì£¼ì˜ í•„ìš”.\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T02:30:45.619228200Z",
     "start_time": "2026-02-25T02:30:04.408468200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Q1: ì•„ì´ì½˜ ë‚˜ì—´ (ì‹œê° ì¸ì‹ ê¸°ì´ˆ)\n",
      "============================================================\n",
      "\n",
      "  ìƒíƒœ: PASS\n",
      "  ì‚¬ìœ : ì‹œê° ì¸ì‹ ì‘ë™ â€” ì–¸ê¸‰ëœ í‚¤ì›Œë“œ: ['ë‚˜ë¬´', 'p']\n",
      "  ì†Œìš”ì‹œê°„: 6.8s\n",
      "  í† í°: prompt=257, completion=808, total=1065\n",
      "  ì‘ë‹µ í…ìŠ¤íŠ¸: ì´ ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ì•„ì´ì½˜/ì´ëª¨ì§€ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì—´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  \n",
      "\n",
      "1. **ë…¹ìƒ‰ ë‚˜ë¬´ ì•„ì´ì½˜** (multiple)  \n",
      "2. **çŒ©çŒ© ì•„ì´ì½˜** (ë¹¨ê°„ìƒ‰ ì‚¬ê°í˜• ì•ˆì— ìœ„ì¹˜í•œ)  \n",
      "3. **P ì•„ì´ì½˜** (íŒŒë€ìƒ‰ ì› ì•ˆì— ìœ„ì¹˜í•œ)  \n",
      "4. **ì†Œë¦¬ê°œ ì•„ì´ì½˜** (ë…¸ë€ìƒ‰ ì‚¬ê°í˜• ì•ˆì— ìœ„ì¹˜í•œ)\n",
      "\n",
      "============================================================\n",
      "  Q2: ë¹¨ê°„ ë°°ê²½ ë°©í–¥ (P ê¸°ì¤€)\n",
      "============================================================\n",
      "\n",
      "  ìƒíƒœ: PASS\n",
      "  ì‚¬ìœ : ì •í™• â€” 'upper\\s*right' íŒ¨í„´ ë§¤ì¹˜\n",
      "  ì†Œìš”ì‹œê°„: 17.1s\n",
      "  í† í°: prompt=294, completion=2000, total=2294\n",
      "  ì‘ë‹µ í…ìŠ¤íŠ¸: Got it, let's try to figure out where the red square is relative to the P. First, I need to visualize the grid. Let's list out the positions. The P is in the center, right? Let's see the grid. The red\n",
      "\n",
      "============================================================\n",
      "  Q3: ë…¸ë€ ë°°ê²½ ë°©í–¥ (P ê¸°ì¤€)\n",
      "============================================================\n",
      "\n",
      "  ìƒíƒœ: PASS\n",
      "  ì‚¬ìœ : ì •í™• â€” 'bottom\\s*right' íŒ¨í„´ ë§¤ì¹˜\n",
      "  ì†Œìš”ì‹œê°„: 17.3s\n",
      "  í† í°: prompt=292, completion=2000, total=2292\n",
      "  ì‘ë‹µ í…ìŠ¤íŠ¸: Got it, let's try to figure out where the yellow background is relative to the P. First, I need to locate the P. In the image, there's a blue circle with a P in the middle. Now, the yellow background \n",
      "\n",
      "============================================================\n",
      "  ê¸°ì´ˆ ì‹œê° ì¸ì‹ ì§„ë‹¨ ê²°ê³¼\n",
      "============================================================\n",
      "  Q1: ì•„ì´ì½˜ ë‚˜ì—´ (ì‹œê° ì¸ì‹ ê¸°ì´ˆ) â†’ PASS âœ“\n",
      "       ì‹œê° ì¸ì‹ ì‘ë™ â€” ì–¸ê¸‰ëœ í‚¤ì›Œë“œ: ['ë‚˜ë¬´', 'p']\n",
      "  Q2: ë¹¨ê°„ ë°°ê²½ ë°©í–¥ (P ê¸°ì¤€) â†’ PASS âœ“\n",
      "       ì •í™• â€” 'upper\\s*right' íŒ¨í„´ ë§¤ì¹˜\n",
      "  Q3: ë…¸ë€ ë°°ê²½ ë°©í–¥ (P ê¸°ì¤€) â†’ PASS âœ“\n",
      "       ì •í™• â€” 'bottom\\s*right' íŒ¨í„´ ë§¤ì¹˜\n",
      "\n",
      "  ì§„ë‹¨ í†µê³¼: 3/3\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ S1: ì›ìˆ­ì´ ì¢Œí‘œ ì¸ì‹ (VLM perception, í…ìŠ¤íŠ¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì¸¡ì • ëŠ¥ë ¥: VLM ì¸ì‹\n",
    "# ì´ë¯¸ì§€ì—ì„œ ë¹¨ê°„ë°°ê²½ ë™ë¬¼ì˜ ì ˆëŒ€ ì¢Œí‘œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë‹µë³€\n",
    "\n",
    "def validate_s1(resp):\n",
    "    coords = extract_coordinates(resp.content)\n",
    "    if not coords:\n",
    "        return False, \"ì¢Œí‘œ ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "    # ì¶”ì¶œëœ ì¢Œí‘œ ì¤‘ MONKEY_POSì— ê°€ê¹Œìš´ ê²ƒì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "    for x, y in coords:\n",
    "        if abs(x - MONKEY_POS[0]) <= COORD_TOLERANCE and abs(y - MONKEY_POS[1]) <= COORD_TOLERANCE:\n",
    "            return True, f\"ì¢Œí‘œ ({x},{y}) â‰ˆ ì •ë‹µ {MONKEY_POS} (ì˜¤ì°¨ Â±{COORD_TOLERANCE} ì´ë‚´)\"\n",
    "    return False, f\"ì¶”ì¶œ ì¢Œí‘œ {coords} â‰  ì •ë‹µ {MONKEY_POS} (ì˜¤ì°¨ Â±{COORD_TOLERANCE} ì´ˆê³¼)\"\n",
    "\n",
    "result = run_vlm_test(\n",
    "    test_id=\"S1\",\n",
    "    title=\"ì›ìˆ­ì´ ì¢Œí‘œ ì¸ì‹ (VLM perception)\",\n",
    "    messages=[\n",
    "        SystemMessage(content=VLM_SYSTEM_MSG),\n",
    "        HumanMessage(content=[\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_URL}},\n",
    "            {\"type\": \"text\", \"text\": (\n",
    "                \"í”Œë ˆì´ì–´(P)ì˜ ì ˆëŒ€ ì¢Œí‘œëŠ” (25,25)ì´ë‹¤.\\n\"\n",
    "                \"ì´ ì´ë¯¸ì§€ëŠ” P ì£¼ë³€ 10x10 ë·°í¬íŠ¸ì´ë‹¤. PëŠ” ë·°í¬íŠ¸ì˜ ì™¼ìª½ì—ì„œ 5ë²ˆì§¸, ìœ„ì—ì„œ 5ë²ˆì§¸ ì¹¸ì— ìˆë‹¤.\\n\"\n",
    "                \"ì˜ˆì‹œ: P ë°”ë¡œ ì˜¤ë¥¸ìª½ ì¹¸ì˜ ì ˆëŒ€ì¢Œí‘œëŠ” (26,25), P ë°”ë¡œ ì•„ë˜ ì¹¸ì€ (25,26)ì´ë‹¤.\\n\"\n",
    "                \"ë¹¨ê°„ìƒ‰ ë°°ê²½ ìœ„ì˜ ë™ë¬¼ì´ P ê¸°ì¤€ìœ¼ë¡œ ë·°í¬íŠ¸ì—ì„œ ëª‡ ì¹¸ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ ì„¸ê³ , ì ˆëŒ€ ì¢Œí‘œë¥¼ (x, y) í˜•íƒœë¡œ ë‹µí•´.\"\n",
    "            )},\n",
    "        ]),\n",
    "    ],\n",
    "    validator=validate_s1,\n",
    ")\n",
    "results.append(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ S2: ê¸°ë¦° ì¢Œí‘œ ì¸ì‹ (VLM perception, í…ìŠ¤íŠ¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì¸¡ì • ëŠ¥ë ¥: VLM ì¸ì‹\n",
    "# ì´ë¯¸ì§€ì—ì„œ ë…¸ë€ë°°ê²½ ë™ë¬¼ì˜ ì ˆëŒ€ ì¢Œí‘œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë‹µë³€\n",
    "\n",
    "def validate_s2(resp):\n",
    "    coords = extract_coordinates(resp.content)\n",
    "    if not coords:\n",
    "        return False, \"ì¢Œí‘œ ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "    for x, y in coords:\n",
    "        if abs(x - GIRAFFE_POS[0]) <= COORD_TOLERANCE and abs(y - GIRAFFE_POS[1]) <= COORD_TOLERANCE:\n",
    "            return True, f\"ì¢Œí‘œ ({x},{y}) â‰ˆ ì •ë‹µ {GIRAFFE_POS} (ì˜¤ì°¨ Â±{COORD_TOLERANCE} ì´ë‚´)\"\n",
    "    return False, f\"ì¶”ì¶œ ì¢Œí‘œ {coords} â‰  ì •ë‹µ {GIRAFFE_POS} (ì˜¤ì°¨ Â±{COORD_TOLERANCE} ì´ˆê³¼)\"\n",
    "\n",
    "result = run_vlm_test(\n",
    "    test_id=\"S2\",\n",
    "    title=\"ê¸°ë¦° ì¢Œí‘œ ì¸ì‹ (VLM perception)\",\n",
    "    messages=[\n",
    "        SystemMessage(content=VLM_SYSTEM_MSG),\n",
    "        HumanMessage(content=[\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_URL}},\n",
    "            {\"type\": \"text\", \"text\": (\n",
    "                \"í”Œë ˆì´ì–´(P)ì˜ ì ˆëŒ€ ì¢Œí‘œëŠ” (25,25)ì´ë‹¤.\\n\"\n",
    "                \"ì´ ì´ë¯¸ì§€ëŠ” P ì£¼ë³€ 10x10 ë·°í¬íŠ¸ì´ë‹¤. PëŠ” ë·°í¬íŠ¸ì˜ ì™¼ìª½ì—ì„œ 5ë²ˆì§¸, ìœ„ì—ì„œ 5ë²ˆì§¸ ì¹¸ì— ìˆë‹¤.\\n\"\n",
    "                \"ì˜ˆì‹œ: P ë°”ë¡œ ì˜¤ë¥¸ìª½ ì¹¸ì˜ ì ˆëŒ€ì¢Œí‘œëŠ” (26,25), P ë°”ë¡œ ì•„ë˜ ì¹¸ì€ (25,26)ì´ë‹¤.\\n\"\n",
    "                \"ë…¸ë€ìƒ‰ ë°°ê²½ ìœ„ì˜ ë™ë¬¼ì´ P ê¸°ì¤€ìœ¼ë¡œ ë·°í¬íŠ¸ì—ì„œ ëª‡ ì¹¸ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ ì„¸ê³ , ì ˆëŒ€ ì¢Œí‘œë¥¼ (x, y) í˜•íƒœë¡œ ë‹µí•´.\"\n",
    "            )},\n",
    "        ]),\n",
    "    ],\n",
    "    validator=validate_s2,\n",
    ")\n",
    "results.append(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ S3: ì›ìˆ­ì´ ì ‘ê·¼ move (VLM + single tool) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì¸¡ì • ëŠ¥ë ¥: VLM + ì¶”ë¡  + tool\n",
    "# ì´ë¯¸ì§€ë¥¼ ë³´ê³  ë¹¨ê°„ë°°ê²½ ë™ë¬¼ì—ê²Œ ì ‘ê·¼í•˜ëŠ” move í˜¸ì¶œ\n",
    "# ê²€ì¦: move í˜¸ì¶œë¨, net dx > 0 (RIGHT), net dy < 0 (UP)\n",
    "\n",
    "game_ctx_s3 = make_game_context(\"ë¹¨ê°„ìƒ‰ ë°°ê²½ì˜ ë™ë¬¼ì—ê²Œ ì ‘ê·¼í•˜ë¼.\")\n",
    "\n",
    "def validate_s3(resp, tool_calls):\n",
    "    if not tool_calls:\n",
    "        return False, \"tool call ì—†ìŒ\"\n",
    "    move_calls = [tc for tc in tool_calls if tc[\"name\"] == \"move\"]\n",
    "    if not move_calls:\n",
    "        return False, f\"move í˜¸ì¶œ ì—†ìŒ (í˜¸ì¶œëœ ë„êµ¬: {[tc['name'] for tc in tool_calls]})\"\n",
    "\n",
    "    dx, dy = 0, 0\n",
    "    for mc in move_calls:\n",
    "        for a in mc[\"args\"].get(\"actions\", []):\n",
    "            d, s = a[\"direction\"], a[\"steps\"]\n",
    "            if d == \"RIGHT\": dx += s\n",
    "            elif d == \"LEFT\": dx -= s\n",
    "            elif d == \"DOWN\": dy += s\n",
    "            elif d == \"UP\": dy -= s\n",
    "\n",
    "    issues = []\n",
    "    if dx <= 0:\n",
    "        issues.append(f\"dx={dx:+d} (expected >0, RIGHT)\")\n",
    "    if dy >= 0:\n",
    "        issues.append(f\"dy={dy:+d} (expected <0, UP)\")\n",
    "\n",
    "    if not issues:\n",
    "        return True, f\"move ë°©í–¥ ì •í™•: dx={dx:+d}(RIGHT), dy={dy:+d}(UP)\"\n",
    "    return False, \", \".join(issues)\n",
    "\n",
    "result = run_test(\n",
    "    test_id=\"S3\",\n",
    "    title=\"ì›ìˆ­ì´ ì ‘ê·¼ move (VLM+ì¶”ë¡ +tool)\",\n",
    "    messages=[\n",
    "        SystemMessage(content=SYSTEM_MSG),\n",
    "        HumanMessage(content=[\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_URL}},\n",
    "            {\"type\": \"text\", \"text\": game_ctx_s3 + \"\\nì´ë¯¸ì§€ì—ì„œ P ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¹¨ê°„ìƒ‰ ë°°ê²½ ë™ë¬¼ì˜ ë°©í–¥ê³¼ ê±°ë¦¬ë¥¼ íŒŒì•…í•´ì„œ move ë„êµ¬ë¥¼ í˜¸ì¶œí•´.\"},\n",
    "        ]),\n",
    "    ],\n",
    "    tools=[move],\n",
    "    validator=validate_s3,\n",
    ")\n",
    "results.append(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ S4: ê¸°ë¦° ì ‘ê·¼ move (VLM + single tool) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì¸¡ì • ëŠ¥ë ¥: VLM + ì¶”ë¡  + tool\n",
    "# ì´ë¯¸ì§€ë¥¼ ë³´ê³  ë…¸ë€ë°°ê²½ ë™ë¬¼ì—ê²Œ ì ‘ê·¼í•˜ëŠ” move í˜¸ì¶œ\n",
    "# ê²€ì¦: move í˜¸ì¶œë¨, net dx > 0 (RIGHT), net dy > 0 (DOWN)\n",
    "\n",
    "game_ctx_s4 = make_game_context(\"ë…¸ë€ìƒ‰ ë°°ê²½ì˜ ë™ë¬¼ì—ê²Œ ì ‘ê·¼í•˜ë¼.\")\n",
    "\n",
    "def validate_s4(resp, tool_calls):\n",
    "    if not tool_calls:\n",
    "        return False, \"tool call ì—†ìŒ\"\n",
    "    move_calls = [tc for tc in tool_calls if tc[\"name\"] == \"move\"]\n",
    "    if not move_calls:\n",
    "        return False, f\"move í˜¸ì¶œ ì—†ìŒ (í˜¸ì¶œëœ ë„êµ¬: {[tc['name'] for tc in tool_calls]})\"\n",
    "\n",
    "    dx, dy = 0, 0\n",
    "    for mc in move_calls:\n",
    "        for a in mc[\"args\"].get(\"actions\", []):\n",
    "            d, s = a[\"direction\"], a[\"steps\"]\n",
    "            if d == \"RIGHT\": dx += s\n",
    "            elif d == \"LEFT\": dx -= s\n",
    "            elif d == \"DOWN\": dy += s\n",
    "            elif d == \"UP\": dy -= s\n",
    "\n",
    "    issues = []\n",
    "    if dx <= 0:\n",
    "        issues.append(f\"dx={dx:+d} (expected >0, RIGHT)\")\n",
    "    if dy <= 0:\n",
    "        issues.append(f\"dy={dy:+d} (expected >0, DOWN)\")\n",
    "\n",
    "    if not issues:\n",
    "        return True, f\"move ë°©í–¥ ì •í™•: dx={dx:+d}(RIGHT), dy={dy:+d}(DOWN)\"\n",
    "    return False, \", \".join(issues)\n",
    "\n",
    "result = run_test(\n",
    "    test_id=\"S4\",\n",
    "    title=\"ê¸°ë¦° ì ‘ê·¼ move (VLM+ì¶”ë¡ +tool)\",\n",
    "    messages=[\n",
    "        SystemMessage(content=SYSTEM_MSG),\n",
    "        HumanMessage(content=[\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_URL}},\n",
    "            {\"type\": \"text\", \"text\": game_ctx_s4 + \"\\nì´ë¯¸ì§€ì—ì„œ P ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë…¸ë€ìƒ‰ ë°°ê²½ ë™ë¬¼ì˜ ë°©í–¥ê³¼ ê±°ë¦¬ë¥¼ íŒŒì•…í•´ì„œ move ë„êµ¬ë¥¼ í˜¸ì¶œí•´.\"},\n",
    "        ]),\n",
    "    ],\n",
    "    tools=[move],\n",
    "    validator=validate_s4,\n",
    ")\n",
    "results.append(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ S5: ì›ìˆ­ì´ í¬íš (VLM + multi-tool) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì¸¡ì • ëŠ¥ë ¥: VLM + ë³µí•© tool\n",
    "# ì´ë¯¸ì§€ë¥¼ ë³´ê³  ë¹¨ê°„ë°°ê²½ ë™ë¬¼ì—ê²Œ ì ‘ê·¼ + í¬íš\n",
    "# ê²€ì¦: move + catch_animal ëª¨ë‘ í˜¸ì¶œë¨\n",
    "\n",
    "game_ctx_s5 = make_game_context(\"ë¹¨ê°„ìƒ‰ ë°°ê²½ì˜ ë™ë¬¼ì„ í¬íší•˜ë¼.\")\n",
    "\n",
    "def validate_s5(resp, tool_calls):\n",
    "    if not tool_calls:\n",
    "        return False, \"tool call ì—†ìŒ\"\n",
    "    names = [tc[\"name\"] for tc in tool_calls]\n",
    "    has_move = \"move\" in names\n",
    "    has_catch = \"catch_animal\" in names\n",
    "\n",
    "    issues = []\n",
    "    if not has_move:\n",
    "        issues.append(\"move ëˆ„ë½\")\n",
    "    if not has_catch:\n",
    "        issues.append(\"catch_animal ëˆ„ë½\")\n",
    "\n",
    "    if not issues:\n",
    "        return True, f\"move + catch_animal ëª¨ë‘ í˜¸ì¶œ ({len(tool_calls)}ê°œ tool calls)\"\n",
    "    return False, f\"{', '.join(issues)} (í˜¸ì¶œëœ ë„êµ¬: {names})\"\n",
    "\n",
    "result = run_test(\n",
    "    test_id=\"S5\",\n",
    "    title=\"ì›ìˆ­ì´ í¬íš (VLM+ë³µí•©tool)\",\n",
    "    messages=[\n",
    "        SystemMessage(content=SYSTEM_MSG),\n",
    "        HumanMessage(content=[\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_URL}},\n",
    "            {\"type\": \"text\", \"text\": game_ctx_s5 + \"\\nì´ë¯¸ì§€ì—ì„œ P ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¹¨ê°„ìƒ‰ ë°°ê²½ ë™ë¬¼ì˜ ë°©í–¥ê³¼ ê±°ë¦¬ë¥¼ íŒŒì•…í•´ì„œ ì ‘ê·¼í•˜ê³  í¬íší•´.\"},\n",
    "        ]),\n",
    "    ],\n",
    "    tools=[move, catch_animal],\n",
    "    validator=validate_s5,\n",
    ")\n",
    "results.append(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# â”€â”€ S6: ì¢…í•© ë¯¸ì…˜ (full workflow) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì¸¡ì • ëŠ¥ë ¥: ì „ì²´ í†µí•©\n",
    "# ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì›ìˆ­ì´ í¬íš + ë°œê²¬ ì„ ì–¸ + ë©”ëª¨ì¥ ê¸°ë¡\n",
    "# ê²€ì¦: move, catch_animal, declare_found, update_notepad ì¤‘ 3ê°œ ì´ìƒ í˜¸ì¶œ\n",
    "\n",
    "game_ctx_s6 = make_game_context(\"ë¹¨ê°„ìƒ‰ ë°°ê²½ì˜ ì›ìˆ­ì´ë¥¼ í¬íší•˜ê³  ë°œê²¬ì„ ì„ ì–¸í•˜ë¼.\")\n",
    "\n",
    "def validate_s6(resp, tool_calls):\n",
    "    if not tool_calls:\n",
    "        return False, \"tool call ì—†ìŒ\"\n",
    "    names = set(tc[\"name\"] for tc in tool_calls)\n",
    "    required = {\"move\", \"catch_animal\", \"declare_found\", \"update_notepad\"}\n",
    "    matched = names & required\n",
    "    missing = required - names\n",
    "\n",
    "    if len(matched) >= 3:\n",
    "        return True, f\"{len(matched)}/4 ë„êµ¬ í˜¸ì¶œ: {matched} (ëˆ„ë½: {missing or 'none'})\"\n",
    "    return False, f\"{len(matched)}/4 ë„êµ¬ë§Œ í˜¸ì¶œ: {matched}, ëˆ„ë½: {missing}\"\n",
    "\n",
    "result = run_test(\n",
    "    test_id=\"S6\",\n",
    "    title=\"ì¢…í•© ë¯¸ì…˜ (full workflow)\",\n",
    "    messages=[\n",
    "        SystemMessage(content=SYSTEM_MSG),\n",
    "        HumanMessage(content=[\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_URL}},\n",
    "            {\"type\": \"text\", \"text\": (\n",
    "                game_ctx_s6 +\n",
    "                \"\\nì´ë¯¸ì§€ì—ì„œ P ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¹¨ê°„ìƒ‰ ë°°ê²½ ì›ìˆ­ì´ì˜ ë°©í–¥ê³¼ ê±°ë¦¬ë¥¼ íŒŒì•…í•´ì„œ \"\n",
    "                \"í¬íší•˜ê³  ë°œê²¬ì„ ì„ ì–¸í•´. ë©”ëª¨ì¥ì— ìƒí™©ì„ ê¸°ë¡í•´.\"\n",
    "            )},\n",
    "        ]),\n",
    "    ],\n",
    "    tools=ALL_TOOLS,\n",
    "    validator=validate_s6,\n",
    ")\n",
    "results.append(result)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# â”€â”€ ê²°ê³¼ ìš”ì•½í‘œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  VLM + Tool Calling ì ì§„ì  ê²€ì¦ ê²°ê³¼\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "ability_map = {\n",
    "    \"S1\": \"VLM ì¸ì‹\",\n",
    "    \"S2\": \"VLM ì¸ì‹\",\n",
    "    \"S3\": \"VLM+ì¶”ë¡ +tool\",\n",
    "    \"S4\": \"VLM+ì¶”ë¡ +tool\",\n",
    "    \"S5\": \"VLM+ë³µí•©tool\",\n",
    "    \"S6\": \"ì „ì²´ í†µí•©\",\n",
    "}\n",
    "\n",
    "stage_map = {\n",
    "    \"S1\": \"ì¸ì‹\",\n",
    "    \"S2\": \"ì¸ì‹\",\n",
    "    \"S3\": \"ì¶”ë¡ +ë„êµ¬\",\n",
    "    \"S4\": \"ì¶”ë¡ +ë„êµ¬\",\n",
    "    \"S5\": \"ë³µí•©ë„êµ¬\",\n",
    "    \"S6\": \"í†µí•©\",\n",
    "}\n",
    "\n",
    "header = f\"  {'ID':<6} {'í…ŒìŠ¤íŠ¸':<28} {'ëŠ¥ë ¥ ë‹¨ê³„':<12} {'ì¸¡ì • ëŠ¥ë ¥':<16} {'ê²°ê³¼':<6} {'í† í°':>8} {'ì‹œê°„':>7}\"\n",
    "print(f\"\\n{header}\")\n",
    "print(f\"  {'-'*6} {'-'*28} {'-'*12} {'-'*16} {'-'*6} {'-'*8} {'-'*7}\")\n",
    "\n",
    "for r in results:\n",
    "    tid = r[\"id\"]\n",
    "    title = r[\"title\"][:26]\n",
    "    stage = stage_map.get(tid, \"\")\n",
    "    ability = ability_map.get(tid, \"\")\n",
    "    status = \"PASS\" if r[\"passed\"] else \"FAIL\"\n",
    "    tok = str(r[\"tokens\"].get(\"total\", \"?\"))\n",
    "    elapsed = f\"{r['elapsed']:.1f}s\"\n",
    "    print(f\"  {tid:<6} {title:<28} {stage:<12} {ability:<16} {status:<6} {tok:>8} {elapsed:>7}\")\n",
    "\n",
    "passed = sum(1 for r in results if r[\"passed\"])\n",
    "total = len(results)\n",
    "print(f\"\\n  í†µê³¼: {passed}/{total}\")\n",
    "\n",
    "# ë‹¨ê³„ë³„ í†µê³¼ìœ¨\n",
    "print(f\"\\n  ë‹¨ê³„ë³„ í†µê³¼ìœ¨:\")\n",
    "for stage_name in [\"ì¸ì‹\", \"ì¶”ë¡ +ë„êµ¬\", \"ë³µí•©ë„êµ¬\", \"í†µí•©\"]:\n",
    "    stage_results = [r for r in results if stage_map.get(r[\"id\"]) == stage_name]\n",
    "    if stage_results:\n",
    "        stage_passed = sum(1 for r in stage_results if r[\"passed\"])\n",
    "        print(f\"    {stage_name}: {stage_passed}/{len(stage_results)}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}