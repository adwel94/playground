{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RunPod GPU ê´€ë¦¬ ë…¸íŠ¸ë¶\n",
    "\n",
    "REST API ì§ì ‘ í˜¸ì¶œ ë°©ì‹ (serverless-mlops íŒ¨í„´).\n",
    "GPUType enumìœ¼ë¡œ íƒ€ì… ì•ˆì „í•˜ê²Œ GPUë¥¼ ì§€ì •í•˜ê³ , pandas DataFrameìœ¼ë¡œ Pod ëª©ë¡ì„ í™•ì¸í•œë‹¤.\n",
    "\n",
    "| GPU       | VRAM | ~$/hr | ìš©ë„          |\n",
    "|-----------|------|------|-------------|\n",
    "| RTX 4090  | 24GB | 0.39 | 2B ëª¨ë¸ í•™ìŠµ/ì¶”ë¡  |\n",
    "| L40S      | 48GB | 0.74 | 7B ëª¨ë¸ ì„œë¹™    |\n",
    "| A100 80GB | 80GB | 1.64 | ëŒ€í˜• ëª¨ë¸       |"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T05:14:59.571734200Z",
     "start_time": "2026-02-17T05:14:59.473567100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "from utils.runpod_client import *\n",
    "\n",
    "print(\"RunPod REST í´ë¼ì´ì–¸íŠ¸ ë¡œë“œ ì™„ë£Œ\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunPod REST í´ë¼ì´ì–¸íŠ¸ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ì…€ 2: Pod ëª©ë¡ ì¡°íšŒ â†’ DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "pod_list = pods()\n",
    "if pod_list:\n",
    "    df = pd.DataFrame(pod_list)\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"ì‹¤í–‰ ì¤‘ì¸ Podì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ì…€ 3: Pod ìƒì„± (GPUType enum ì‚¬ìš©)\n",
    "pod_id = create(\n",
    "    name=\"my-workspace\",\n",
    "    gpu_id=GPUType.NVIDIA_GEFORCE_RTX_4090,\n",
    "    gpu_count=1,\n",
    "    volume=50,\n",
    "    image_name=\"runpod/pytorch:2.4.0-py3.11-cuda12.4.1-devel-ubuntu22.04\",\n",
    ")\n",
    "print(f\"ìƒì„±ëœ Pod ID: {pod_id}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ì…€ 4: íŠ¹ì • Pod ìƒíƒœ ì¡°íšŒ\n",
    "# pod_id = \"POD_ID\"\n",
    "pod_info = pod(pod_id)\n",
    "pod_info"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ì…€ 5: Pod ì‚­ì œ\n",
    "# pod_id = \"POD_ID\"\n",
    "result = delete(\"6bo9b41ss21l6t\")\n",
    "print(f\"ì‚­ì œ ê²°ê³¼: {result}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ì…€ 6: VLM ì„œë¹™ Pod ìƒì„±\n",
    "vlm_pod_id = create_from_template(\n",
    "    name=\"qwen3-vl-4b-serving\",\n",
    "    gpu_id=GPUType.NVIDIA_GEFORCE_RTX_5080,\n",
    ")\n",
    "print(f\"VLM Pod ID: {vlm_pod_id}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T05:15:44.861822900Z",
     "start_time": "2026-02-17T05:15:19.938587500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ì…€ 7: vLLM ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "VLLM_BASE_URL = \"https://api.runpod.ai/v2/8iiebdj6zt0fbd/openai/v1\" # ì˜ˆ: http://your-pod-ip:8000/v1\n",
    "MODEL_NAME = \"qwen/qwen3-vl-4b-thinking-fp8\"\n",
    "\n",
    "if VLLM_BASE_URL != \"ì—¬ê¸°ì—_URLì„_ì…ë ¥í•˜ì„¸ìš”\":\n",
    "    llm = ChatOpenAI(\n",
    "        base_url=VLLM_BASE_URL,\n",
    "        model=MODEL_NAME,\n",
    "        temperature=0,\n",
    "        api_key=os.getenv(\"RUNPOD_API_KEY\")\n",
    "    )\n",
    "\n",
    "    response = llm.invoke([\n",
    "        HumanMessage(content=\"ì•ˆë…•! ë„ˆëŠ” ì–´ë–¤ ëª¨ë¸ì´ë‹ˆ? ë„êµ¬ í˜¸ì¶œì´ ê°€ëŠ¥í•˜ë‹ˆ?\")\n",
    "    ])\n",
    "    print(\"\\n[ì‘ë‹µ ê²°ê³¼]\")\n",
    "    print(response.content)\n",
    "else:\n",
    "    print(\"VLLM_BASE_URLì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì‘ë‹µ ê²°ê³¼]\n",
      "Okay, the user is asking, \"ì•ˆë…•! ë„ˆëŠ” ì–´ë–¤ ëª¨ë¸ì´ë‹ˆ? ë„êµ¬ í˜¸ì¶œì´ ê°€ëŠ¥í•˜ë‹ˆ?\" which translates to \"Hello! What kind of model are you? Can you call tools?\" \n",
      "\n",
      "First, I need to identify the user's intent. They want to know my model type and if I can use tools. Since they're asking in Korean, I should respond in Korean as well.\n",
      "\n",
      "I should start by introducing myself as Qwen, the large language model developed by Tongyi Lab. Mention my capabilities like answering questions, creating text, coding, etc.\n",
      "\n",
      "Next, the user is asking about tool calling. I need to clarify that while I can't directly call external tools, I can use the tools provided by Alibaba Cloud, like the Tongyi app or other integrated services. Maybe mention that I can help with specific tasks if they provide the necessary information.\n",
      "\n",
      "Wait, the user might be confused about what \"ë„êµ¬ í˜¸ì¶œ\" means. In some contexts, tool calling refers to accessing external APIs or services. I should explain that while I can't call arbitrary tools, I can use the tools available within the platform, like the Tongyi app or other integrated services.\n",
      "\n",
      "Also, I should check if there are any specific tools the user is referring to. Maybe they're thinking of something like a calculator or a database query. But since I'm a large language model, I can't access external data, so I need to be clear about that.\n",
      "\n",
      "I should structure the response: first, introduce myself, then explain my capabilities, then address tool calling. Make sure to be clear and helpful, avoiding technical jargon.\n",
      "\n",
      "Wait, the user might be referring to the ability to use tools like the Qwen API or other services. Maybe they want to know if I can interact with external APIs. But in the context of the Qwen model, I can't directly call external tools unless it's through the Alibaba Cloud platform.\n",
      "\n",
      "So, the answer should be: I'm Qwen, a large language model. I can answer questions, write text, code, etc. Regarding tool calling, I can't directly access external tools, but I can use the tools provided by Alibaba Cloud, like the Tongyi app or other integrated services. If you have specific tasks, I can help with them.\n",
      "\n",
      "Wait, but the user might be asking if I can call tools like a calculator or a database. Since I can't access external data, I should mention that I can't perform real-time data queries but can help with tasks based on my training data.\n",
      "\n",
      "Also, maybe the user is confused between different models. For example, some models like GPT have tool calling capabilities, but Qwen might not. So, I need to clarify that while I can't call external tools, I can assist with tasks within my capabilities.\n",
      "\n",
      "Let me check the official documentation. Qwen does support some integrated tools through Alibaba Cloud, but not arbitrary external ones. So, the answer should be that I can't call external tools but can use the tools provided by the platform.\n",
      "\n",
      "So, the response should be: ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ê°œë°œí•œ ì´ˆëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì¸ Qwenì…ë‹ˆë‹¤. ì €ëŠ” ì§ˆë¬¸ì— ë‹µí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ ìƒì„±, ì½”ë“œ ì‘ì„± ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„êµ¬ í˜¸ì¶œ(ì˜ˆ: ì™¸ë¶€ API í˜¸ì¶œ)ì€ ì œê°€ ì§ì ‘ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ì œê³µí•˜ëŠ” í†µí•© ì„œë¹„ìŠ¤(ì˜ˆ: í†µì˜ ì•±, ê¸°íƒ€ ì¸í„°ê·¸ë ˆì´í‹°ë“œ ì„œë¹„ìŠ¤)ë¥¼ í™œìš©í•˜ì—¬ íŠ¹ì • ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ êµ¬ì²´ì ì¸ ì‘ì—…ì´ í•„ìš”í•˜ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”, ì œê°€ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "Wait, but the user is asking if tool calling is possible. So, I need to be clear that while I can't call external tools, I can use the tools provided by the platform. Maybe the user is thinking of something like the ability to access a calculator or a database. But since I can't, I should explain that.\n",
      "\n",
      "Also, maybe the user is referring to the ability to use tools like the Qwen API. But in the context of the model itself, I can't call external tools unless it's through the platform.\n",
      "\n",
      "So, the answer should be: I am Qwen, a large language model developed by Tongyi Lab. I can answer questions, write text, code, etc. Regarding tool calling, I cannot directly access external tools, but I can use the tools provided by Alibaba Cloud, such as the Tongyi app or other integrated services. If you have specific tasks, I can help with them.\n",
      "\n",
      "Wait, the user is asking in Korean, so the response should be in Korean. Let me make sure the translation is accurate.\n",
      "\n",
      "\"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ê°œë°œí•œ ì´ˆëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì¸ Qwenì…ë‹ˆë‹¤. ì €ëŠ” ì§ˆë¬¸ì— ë‹µí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ ìƒì„±, ì½”ë“œ ì‘ì„± ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„êµ¬ í˜¸ì¶œ(ì˜ˆ: ì™¸ë¶€ API í˜¸ì¶œ)ì€ ì œê°€ ì§ì ‘ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ì œê³µí•˜ëŠ” í†µí•© ì„œë¹„ìŠ¤(ì˜ˆ: í†µì˜ ì•±, ê¸°íƒ€ ì¸í„°ê·¸ë ˆì´í‹°ë“œ ì„œë¹„ìŠ¤)ë¥¼ í™œìš©í•˜ì—¬ íŠ¹ì • ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ êµ¬ì²´ì ì¸ ì‘ì—…ì´ í•„ìš”í•˜ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”, ì œê°€ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\n",
      "\n",
      "Wait, but the user might not know about the Tongyi app. Maybe it's better to say \"Tongyi app\" or \"Tongyi services\" in Korean.\n",
      "\n",
      "Alternatively, maybe the user is referring to the ability to use tools like the Qwen API. But in the context of the model, I can't call external tools unless it's through the platform.\n",
      "\n",
      "Another point: the user might be confused between different models. For example, some models like GPT-4 can call tools, but Qwen might not. So, I need to clarify that while I can't call external tools, I can assist with tasks within my capabilities.\n",
      "\n",
      "Wait, but the user is asking if tool calling is possible. So, the answer should be: I can't call external tools, but I can use the tools provided by the platform.\n",
      "\n",
      "Let me check if there's any official info. According to the Qwen documentation, Qwen does not support direct tool calling, but it can interact with the Alibaba Cloud services. So, the answer should be that I can't call external tools but can use the tools provided by Alibaba Cloud.\n",
      "\n",
      "So, the response should be: ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ê°œë°œí•œ ì´ˆëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì¸ Qwenì…ë‹ˆë‹¤. ì €ëŠ” ì§ˆë¬¸ì— ë‹µí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ ìƒì„±, ì½”ë“œ ì‘ì„± ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„êµ¬ í˜¸ì¶œ(ì˜ˆ: ì™¸ë¶€ API í˜¸ì¶œ)ì€ ì œê°€ ì§ì ‘ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ì œê³µí•˜ëŠ” í†µí•© ì„œë¹„ìŠ¤(ì˜ˆ: í†µì˜ ì•±, ê¸°íƒ€ ì¸í„°ê·¸ë ˆì´í‹°ë“œ ì„œë¹„ìŠ¤)ë¥¼ í™œìš©í•˜ì—¬ íŠ¹ì • ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ êµ¬ì²´ì ì¸ ì‘ì—…ì´ í•„ìš”í•˜ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”, ì œê°€ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "Wait, but the user might not know about the Tongyi app. Maybe it's better to say \"Tongyi app\" in English but translated to Korean. Or maybe \"í†µì˜ ì•±\" is the correct term.\n",
      "\n",
      "Alternatively, maybe the user is referring to the ability to use tools like a calculator or a database. Since I can't access external data, I should mention that I can't perform real-time data queries but can help with tasks based on my training data.\n",
      "\n",
      "So, the response should be: ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ê°œë°œí•œ ì´ˆëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì¸ Qwenì…ë‹ˆë‹¤. ì €ëŠ” ì§ˆë¬¸ì— ë‹µí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ ìƒì„±, ì½”ë“œ ì‘ì„± ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„êµ¬ í˜¸ì¶œ(ì˜ˆ: ì™¸ë¶€ API í˜¸ì¶œ)ì€ ì œê°€ ì§ì ‘ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ì œê³µí•˜ëŠ” í†µí•© ì„œë¹„ìŠ¤(ì˜ˆ: í†µì˜ ì•±, ê¸°íƒ€ ì¸í„°ê·¸ë ˆì´í‹°ë“œ ì„œë¹„ìŠ¤)ë¥¼ í™œìš©í•˜ì—¬ íŠ¹ì • ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ êµ¬ì²´ì ì¸ ì‘ì—…ì´ í•„ìš”í•˜ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”, ì œê°€ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "Wait, but the user might be asking if I can call tools like a calculator. So, maybe I should clarify that I can't access external tools but can help with calculations if I have the necessary information.\n",
      "\n",
      "Alternatively, maybe the user is confused between different models. For example, some models like GPT-4 can call tools, but Qwen might not. So, I need to clarify that while I can't call external tools, I can assist with tasks within my capabilities.\n",
      "\n",
      "Wait, but the user is asking if tool calling is possible. So, the answer should be: I can't call external tools, but I can use the tools provided by the platform.\n",
      "\n",
      "Let me check the exact wording. The user says \"ë„êµ¬ í˜¸ì¶œì´ ê°€ëŠ¥í•˜ë‹ˆ?\" which translates to \"Can tool calling be done?\" So, the answer should be: No, I can't directly call external tools, but I can use the tools provided by Alibaba Cloud.\n",
      "\n",
      "So, the response should be: ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ê°œë°œí•œ ì´ˆëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì¸ Qwenì…ë‹ˆë‹¤. ì €ëŠ” ì§ˆë¬¸ì— ë‹µí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ ìƒì„±, ì½”ë“œ ì‘ì„± ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„êµ¬ í˜¸ì¶œ(ì˜ˆ: ì™¸ë¶€ API í˜¸ì¶œ)ì€ ì œê°€ ì§ì ‘ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ì œê³µí•˜ëŠ” í†µí•© ì„œë¹„ìŠ¤(ì˜ˆ: í†µì˜ ì•±, ê¸°íƒ€ ì¸í„°ê·¸ë ˆì´í‹°ë“œ ì„œë¹„ìŠ¤)ë¥¼ í™œìš©í•˜ì—¬ íŠ¹ì • ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ êµ¬ì²´ì ì¸ ì‘ì—…ì´ í•„ìš”í•˜ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”, ì œê°€ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "Wait, but maybe the user is referring to the ability to use tools like the Qwen API. But in the context of the model itself, I can't call external tools unless it's through the platform.\n",
      "\n",
      "Alternatively, maybe the user is asking if I can call tools like a calculator. So, I should say that I can't access external tools but can help with calculations if I have the necessary information.\n",
      "\n",
      "Wait, but the user is asking if tool calling is possible. So, the answer should be: I can't call external tools, but I can use the tools provided by the platform.\n",
      "\n",
      "I think the response is correct as above. Let me make sure the translation is accurate.\n",
      "\n",
      "\"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ê°œë°œí•œ ì´ˆëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì¸ Qwenì…ë‹ˆë‹¤. ì €ëŠ” ì§ˆë¬¸ì— ë‹µí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ ìƒì„±, ì½”ë“œ ì‘ì„± ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„êµ¬ í˜¸ì¶œ(ì˜ˆ: ì™¸ë¶€ API í˜¸ì¶œ)ì€ ì œê°€ ì§ì ‘ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ì œê³µí•˜ëŠ” í†µí•© ì„œë¹„ìŠ¤(ì˜ˆ: í†µì˜ ì•±, ê¸°íƒ€ ì¸í„°ê·¸ë ˆì´í‹°ë“œ ì„œë¹„ìŠ¤)ë¥¼ í™œìš©í•˜ì—¬ íŠ¹ì • ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ êµ¬ì²´ì ì¸ ì‘ì—…ì´ í•„ìš”í•˜ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”, ì œê°€ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\n",
      "\n",
      "Yes, this should be correct.\n",
      "</think>\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ê°œë°œí•œ ì´ˆëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì¸ **Qwen**ì…ë‹ˆë‹¤. ì €ëŠ” ì§ˆë¬¸ì— ë‹µí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ ìƒì„±, ì½”ë“œ ì‘ì„±, ë…¼ë¦¬ì  ì¶”ë¡ , ì°½ì˜ì  ì½˜í…ì¸  ì‘ì„± ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "### ë„êµ¬ í˜¸ì¶œì— ëŒ€í•œ ì„¤ëª…:\n",
      "- **ì™¸ë¶€ ë„êµ¬ í˜¸ì¶œ(ì˜ˆ: API, ë°ì´í„°ë² ì´ìŠ¤)**ì€ ì§ì ‘ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  \n",
      "- ê·¸ëŸ¬ë‚˜ **ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ì œê³µí•˜ëŠ” í†µí•© ì„œë¹„ìŠ¤**(ì˜ˆ: í†µì˜ ì•±, ê¸°íƒ€ ì¸í„°ê·¸ë ˆì´í‹°ë“œ ì„œë¹„ìŠ¤)ë¥¼ í™œìš©í•´ íŠ¹ì • ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "- ì˜ˆë¥¼ ë“¤ì–´, ê³„ì‚°, ë¬¸ì„œ ìƒì„±, ì½”ë“œ ì‹¤í–‰ ë“± **í”Œë«í¼ ë‚´ì—ì„œ ì§€ì›ë˜ëŠ” ê¸°ëŠ¥**ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë§Œì•½ êµ¬ì²´ì ì¸ ì‘ì—…ì´ í•„ìš”í•˜ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”! ğŸ˜Š  \n",
      "(ì˜ˆ: \"1000ì„ 2ë¡œ ë‚˜ëˆ„ì–´ ë´…ì‹œë‹¤\", \"Python ì½”ë“œë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•´ ì£¼ì„¸ìš”\")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "# ì…€ 8: vLLM Tool Calling ë””ë²„ê·¸\n# LangChain bind_tools vs raw HTTP ë¹„êµë¡œ tool call ë¯¸ìƒì„± ì›ì¸ íŒŒì•…\nimport requests as _requests, json as _json\nfrom langchain_core.tools import tool\nfrom pydantic import BaseModel, Field\n\n# â”€â”€ 1) Tool ì •ì˜ (move í•˜ë‚˜ë§Œ ê°„ë‹¨íˆ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass Action(BaseModel):\n    direction: str = Field(description=\"ì´ë™ ë°©í–¥\", enum=[\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"])\n    steps: int = Field(description=\"ì´ë™ ì¹¸ìˆ˜ (1~3)\")\n\nclass MoveArgs(BaseModel):\n    actions: list[Action] = Field(description=\"ìµœëŒ€ 4ê°œ í–‰ë™ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰\")\n\n@tool(args_schema=MoveArgs)\ndef move(actions: list[Action]) -> str:\n    \"\"\"í”Œë ˆì´ì–´ë¥¼ ì´ë™ì‹œí‚¨ë‹¤.\"\"\"\n    return \"ok\"\n\nTEST_PROMPT = \"ë„ˆëŠ” ê²©ì ë§µ ìœ„ì˜ í”Œë ˆì´ì–´ì•¼. í˜„ì¬ (0,0)ì— ìˆê³  ëª©í‘œëŠ” (2,1)ì´ì•¼. move ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì´ë™í•´.\"\n\n# â”€â”€ 2) LangChain bind_tools ë°©ì‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"=\" * 60)\nprint(\"[LangChain bind_tools ë°©ì‹]\")\nprint(\"=\" * 60)\n\nllm_with_tools = llm.bind_tools([move])\nlc_resp = llm_with_tools.invoke(TEST_PROMPT)\n\nprint(f\"\\nğŸ“Œ type        : {type(lc_resp).__name__}\")\nprint(f\"ğŸ“Œ content     :\\n{lc_resp.content[:500] if lc_resp.content else '(empty)'}\")\nprint(f\"ğŸ“Œ tool_calls  : {lc_resp.tool_calls}\")\nprint(f\"ğŸ“Œ additional_kwargs : {_json.dumps(lc_resp.additional_kwargs, indent=2, ensure_ascii=False)}\")\n\n# â”€â”€ 3) Raw HTTP ë°©ì‹ (OpenAI format) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"\\n\" + \"=\" * 60)\nprint(\"[Raw HTTP ë°©ì‹ â€” vLLM ì§ì ‘ í˜¸ì¶œ]\")\nprint(\"=\" * 60)\n\nraw_tools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"move\",\n            \"description\": \"í”Œë ˆì´ì–´ë¥¼ ì´ë™ì‹œí‚¨ë‹¤. ìµœëŒ€ 4ê°œ í–‰ë™ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"actions\": {\n                        \"type\": \"array\",\n                        \"items\": {\n                            \"type\": \"object\",\n                            \"properties\": {\n                                \"direction\": {\"type\": \"string\", \"enum\": [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]},\n                                \"steps\": {\"type\": \"integer\"},\n                            },\n                            \"required\": [\"direction\", \"steps\"],\n                        },\n                    }\n                },\n                \"required\": [\"actions\"],\n            },\n        },\n    }\n]\n\npayload = {\n    \"model\": MODEL_NAME,\n    \"messages\": [{\"role\": \"user\", \"content\": TEST_PROMPT}],\n    \"tools\": raw_tools,\n    \"temperature\": 0,\n}\n\nraw_resp = _requests.post(\n    f\"{VLLM_BASE_URL}/chat/completions\",\n    headers={\"Authorization\": f\"Bearer {os.getenv('RUNPOD_API_KEY')}\"},\n    json=payload,\n    timeout=120,\n)\n\nprint(f\"\\nğŸ“Œ status_code : {raw_resp.status_code}\")\nraw_json = raw_resp.json()\nprint(f\"ğŸ“Œ raw JSON    :\\n{_json.dumps(raw_json, indent=2, ensure_ascii=False)}\")\n\n# â”€â”€ 4) ìš”ì•½ ë¹„êµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"\\n\" + \"=\" * 60)\nprint(\"[ë¹„êµ ìš”ì•½]\")\nprint(\"=\" * 60)\nlc_has_tool = bool(lc_resp.tool_calls)\nraw_choices = raw_json.get(\"choices\", [{}])\nraw_has_tool = bool(raw_choices[0].get(\"message\", {}).get(\"tool_calls\"))\nprint(f\"  LangChain tool_calls ì¡´ì¬: {lc_has_tool}\")\nprint(f\"  Raw HTTP  tool_calls ì¡´ì¬: {raw_has_tool}\")\nif raw_has_tool and not lc_has_tool:\n    print(\"  â†’ vLLMì€ tool callì„ ìƒì„±í•˜ì§€ë§Œ LangChain íŒŒì‹±ì—ì„œ ëˆ„ë½ë¨ (LangChain ì´ìŠˆ)\")\nelif not raw_has_tool and not lc_has_tool:\n    print(\"  â†’ vLLM ì„œë²„ ìì²´ê°€ tool callì„ ìƒì„±í•˜ì§€ ì•ŠìŒ (ëª¨ë¸/ì„œë²„ ì„¤ì • ì´ìŠˆ)\")\nelif raw_has_tool and lc_has_tool:\n    print(\"  â†’ ì–‘ìª½ ëª¨ë‘ ì •ìƒ ë™ì‘\")\n",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T05:16:16.140133900Z",
     "start_time": "2026-02-17T05:15:49.779737Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hun41\\AppData\\Local\\Temp\\ipykernel_27744\\2607549183.py:9: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'enum'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  direction: str = Field(description=\"ì´ë™ ë°©í–¥\", enum=[\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[LangChain bind_tools ë°©ì‹]\n",
      "============================================================\n",
      "\n",
      "ğŸ“Œ type        : AIMessage\n",
      "ğŸ“Œ content     :\n",
      "Okay, let's see. The user is a player on a grid map starting at (0,0) and needs to get to (2,1). They want me to use the move tool to help.\n",
      "\n",
      "First, I need to figure out the direction and steps required. The current position is (0,0), target is (2,1). So, the x-coordinate needs to go from 0 to 2, which is a difference of +2. The y-coordinate needs to go from 0 to 1, which is +1.\n",
      "\n",
      "But the move function allows up to 4 actions, each with direction (UP, DOWN, LEFT, RIGHT) and steps (1-3). So, maybe I\n",
      "ğŸ“Œ tool_calls  : [{'name': 'move', 'args': {'actions': [{'direction': 'RIGHT', 'steps': 2}, {'direction': 'UP', 'steps': 1}]}, 'id': 'chatcmpl-tool-8d81501f9185445b', 'type': 'tool_call'}]\n",
      "ğŸ“Œ additional_kwargs : {\n",
      "  \"refusal\": null\n",
      "}\n",
      "\n",
      "============================================================\n",
      "[Raw HTTP ë°©ì‹ â€” vLLM ì§ì ‘ í˜¸ì¶œ]\n",
      "============================================================\n",
      "\n",
      "ğŸ“Œ status_code : 200\n",
      "ğŸ“Œ raw JSON    :\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"annotations\": null,\n",
      "        \"audio\": null,\n",
      "        \"content\": \"Okay, let's see. The user is a player on a grid map starting at (0,0) and needs to get to (2,1). They want me to use the move tool to help.\\n\\nFirst, I need to figure out the direction and steps required. The target is (2,1), so from (0,0), moving right twice would get to x=2, but y stays 0. Then moving up once would take y to 1. Wait, but the coordinates might be (x,y), so moving right increases x, up increases y.\\n\\nWait, the starting point is (0,0), target (2,1). So the difference in x is +2, y is +1. So the player needs to move right 2 steps and up 1 step. But the move function allows up to 4 actions. So maybe two actions: right 2 steps and up 1 step. But the problem says \\\"ìµœëŒ€ 4ê°œ í–‰ë™ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰\\\", so maybe split into multiple steps.\\n\\nWait, the move function's parameters are an array of actions, each with direction and steps. So each action is a single move in a direction for a certain number of steps.\\n\\nSo from (0,0) to (2,1), the required steps are right 2 and up 1. So two actions: first right 2, then up 1. But maybe the user expects the exact steps. Let me check the coordinates.\\n\\nWait, (0,0) to (2,1): x increases by 2, y increases by 1. So moving right 2 steps would take x from 0 to 2, y remains 0. Then moving up 1 step would take y from 0 to 1. So total two actions: [ {direction: \\\"RIGHT\\\", steps: 2}, {direction: \\\"UP\\\", steps: 1} ].\\n\\nBut the problem says \\\"ìµœëŒ€ 4ê°œ í–‰ë™ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰\\\", so maybe the user can have up to 4 actions, but in this case, two are sufficient. So the correct move sequence is right 2, then up 1.\\n\\nWait, but maybe the grid is such that moving right 2 steps is possible. Let me confirm. The starting point is (0,0), so moving right 1 step would be (1,0), right 2 steps (2,0), then up 1 step (2,1). Yes, that's correct.\\n\\nSo the tool call should have two actions: first RIGHT with steps 2, then UP with steps 1.\\n\\nWait, but the parameters for the move function require an array of actions. Each action is an object with direction and steps. So the arguments would be:\\n\\n{\\n  \\\"actions\\\": [\\n    {\\\"direction\\\": \\\"RIGHT\\\", \\\"steps\\\": 2},\\n    {\\\"direction\\\": \\\"UP\\\", \\\"steps\\\": 1}\\n  ]\\n}\\n\\nBut let me check if the directions are correct. In grid maps, usually, UP is positive y, DOWN negative y, LEFT negative x, RIGHT positive x. So yes, moving RIGHT increases x, UP increases y.\\n\\nSo the correct sequence is right 2, then up 1. Therefore, the tool call should be as above.\\n\\nWait, but maybe the user expects the steps to be in a different order? Like, maybe moving up first? But (0,0) to (2,1) requires x to increase by 2 and y by 1. So moving up first would take y to 1, but x is still 0, so then need to move right 2. But that's also possible. However, the problem doesn't specify any obstacles, so either order is possible. But the minimal steps would be right then up, or up then right. However, the problem says \\\"move ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì´ë™í•´\\\" so the user probably wants the shortest path.\\n\\nBut the problem doesn't specify if the grid has obstacles, so assuming it's a straight path. So the correct path is right 2, up 1.\\n\\nWait, but maybe the user expects the steps to be in the order of the directions. Let me check the problem statement again. The user says \\\"í˜„ì¬ (0,0)ì— ìˆê³  ëª©í‘œëŠ” (2,1)ì´ì•¼.\\\" So from (0,0) to (2,1), the required movement is 2 right and 1 up.\\n\\nSo the correct move sequence is two actions: right 2 steps, then up 1 step.\\n\\nTherefore, the tool call should be:\\n\\n{\\n  \\\"name\\\": \\\"move\\\",\\n  \\\"arguments\\\": {\\n    \\\"actions\\\": [\\n      {\\\"direction\\\": \\\"RIGHT\\\", \\\"steps\\\": 2},\\n      {\\\"direction\\\": \\\"UP\\\", \\\"steps\\\": 1}\\n    ]\\n  }\\n}\\n\\nYes, that should work. Let me check if the parameters are correct. The function requires an array of actions, each with direction (enum: UP, DOWN, LEFT, RIGHT) and steps (integer). So each action is correctly specified.\\n\\nSo the answer should be a tool call with those two actions.\\n</think>\\n\\n\",\n",
      "        \"function_call\": null,\n",
      "        \"reasoning\": null,\n",
      "        \"reasoning_content\": null,\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"actions\\\": [{\\\"direction\\\": \\\"RIGHT\\\", \\\"steps\\\": 2}, {\\\"direction\\\": \\\"UP\\\", \\\"steps\\\": 1}]}\",\n",
      "              \"name\": \"move\"\n",
      "            },\n",
      "            \"id\": \"chatcmpl-tool-970c79d2d53eb267\",\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"stop_reason\": null,\n",
      "      \"token_ids\": null\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1771305363,\n",
      "  \"id\": \"chatcmpl-b2738a1c05840f7a\",\n",
      "  \"kv_transfer_params\": null,\n",
      "  \"model\": \"qwen/qwen3-vl-4b-thinking-fp8\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"prompt_logprobs\": null,\n",
      "  \"prompt_token_ids\": null,\n",
      "  \"service_tier\": null,\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1104,\n",
      "    \"prompt_tokens\": 260,\n",
      "    \"prompt_tokens_details\": null,\n",
      "    \"total_tokens\": 1364\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "[ë¹„êµ ìš”ì•½]\n",
      "============================================================\n",
      "  LangChain tool_calls ì¡´ì¬: True\n",
      "  Raw HTTP  tool_calls ì¡´ì¬: True\n",
      "  â†’ ì–‘ìª½ ëª¨ë‘ ì •ìƒ ë™ì‘\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "# ì…€ 9: vLLM Tool Calling ë””ë²„ê·¸ â€” ì´ë¯¸ì§€(multimodal) ì…ë ¥ í…ŒìŠ¤íŠ¸\n# ê°€ì„¤: ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ë³´ë‚´ë©´ tool callingì´ ê¹¨ì§€ëŠ”ì§€ í™•ì¸\n# cell-8ì˜ llm, VLLM_BASE_URL, MODEL_NAME, raw_tools ì¬ì‚¬ìš©\nimport base64 as _base64, io as _io\nfrom PIL import Image as _Image, ImageDraw as _ImageDraw\n\n# â”€â”€ 1) ê°„ë‹¨í•œ 10x10 ê²©ì PNG ìƒì„± â†’ base64 data URL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimg = _Image.new(\"RGB\", (100, 100), \"white\")\ndraw = _ImageDraw.Draw(img)\nfor i in range(0, 101, 10):\n    draw.line([(i, 0), (i, 100)], fill=\"black\", width=1)\n    draw.line([(0, i), (100, i)], fill=\"black\", width=1)\n# í”Œë ˆì´ì–´(0,0)=ë¹¨ê°„ ì , ëª©í‘œ(2,1)=ì´ˆë¡ ì \ndraw.ellipse([2, 82, 8, 88], fill=\"red\")      # (0,0) â†’ ì™¼ìª½ í•˜ë‹¨\ndraw.ellipse([22, 72, 28, 78], fill=\"green\")   # (2,1) â†’ ì˜¤ë¥¸ìª½ ìœ„\nbuf = _io.BytesIO()\nimg.save(buf, format=\"PNG\")\nb64_str = _base64.b64encode(buf.getvalue()).decode()\nimage_data_url = f\"data:image/png;base64,{b64_str}\"\nprint(f\"âœ… í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (base64 ê¸¸ì´: {len(b64_str)})\")\n\n# â”€â”€ 2) LangChain bind_tools + ì´ë¯¸ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"\\n\" + \"=\" * 60)\nprint(\"[LangChain bind_tools + ì´ë¯¸ì§€]\")\nprint(\"=\" * 60)\n\nfrom langchain_core.messages import HumanMessage as _HM\n\nlc_msg = _HM(content=[\n    {\"type\": \"text\", \"text\": TEST_PROMPT},\n    {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}},\n])\n\nllm_with_tools = llm.bind_tools([move])\n\ntry:\n    lc_img_resp = llm_with_tools.invoke([lc_msg])\n    print(f\"\\nğŸ“Œ type        : {type(lc_img_resp).__name__}\")\n    print(f\"ğŸ“Œ content     :\\n{lc_img_resp.content[:500] if lc_img_resp.content else '(empty)'}\")\n    print(f\"ğŸ“Œ tool_calls  : {lc_img_resp.tool_calls}\")\n    lc_img_has_tool = bool(lc_img_resp.tool_calls)\nexcept Exception as e:\n    print(f\"\\nâŒ LangChain ì—ëŸ¬: {e}\")\n    lc_img_has_tool = False\n\n# â”€â”€ 3) Raw HTTP + ì´ë¯¸ì§€ (ì‚¬íŒŒë¦¬ ì—ì´ì „íŠ¸ ë™ì¼ êµ¬ì¡°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"\\n\" + \"=\" * 60)\nprint(\"[Raw HTTP + ì´ë¯¸ì§€ â€” ì‚¬íŒŒë¦¬ ì—ì´ì „íŠ¸ ë™ì¼ êµ¬ì¡°]\")\nprint(\"=\" * 60)\n\npayload_img = {\n    \"model\": MODEL_NAME,\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": TEST_PROMPT},\n                {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}},\n            ],\n        }\n    ],\n    \"tools\": raw_tools,\n    \"temperature\": 0,\n}\n\ntry:\n    raw_img_resp = _requests.post(\n        f\"{VLLM_BASE_URL}/chat/completions\",\n        headers={\"Authorization\": f\"Bearer {os.getenv('RUNPOD_API_KEY')}\"},\n        json=payload_img,\n        timeout=120,\n    )\n    print(f\"\\nğŸ“Œ status_code : {raw_img_resp.status_code}\")\n    raw_img_json = raw_img_resp.json()\n    print(f\"ğŸ“Œ raw JSON    :\\n{_json.dumps(raw_img_json, indent=2, ensure_ascii=False)}\")\n    raw_img_choices = raw_img_json.get(\"choices\", [{}])\n    raw_img_has_tool = bool(raw_img_choices[0].get(\"message\", {}).get(\"tool_calls\"))\nexcept Exception as e:\n    print(f\"\\nâŒ Raw HTTP ì—ëŸ¬: {e}\")\n    raw_img_json = {}\n    raw_img_has_tool = False\n\n# â”€â”€ 4) ë¹„êµ ìš”ì•½: í…ìŠ¤íŠ¸ ì „ìš© vs ì´ë¯¸ì§€ í¬í•¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"\\n\" + \"=\" * 60)\nprint(\"[ë¹„êµ ìš”ì•½: í…ìŠ¤íŠ¸ ì „ìš© (cell-8) vs ì´ë¯¸ì§€ í¬í•¨ (cell-9)]\")\nprint(\"=\" * 60)\nprint(f\"  {'ë°©ì‹':<30} {'í…ìŠ¤íŠ¸ë§Œ':>10} {'í…ìŠ¤íŠ¸+ì´ë¯¸ì§€':>14}\")\nprint(f\"  {'-'*30} {'-'*10} {'-'*14}\")\nprint(f\"  {'LangChain bind_tools':<30} {'O':>10} {'O' if lc_img_has_tool else 'X':>14}\")\nprint(f\"  {'Raw HTTP':<30} {'O':>10} {'O' if raw_img_has_tool else 'X':>14}\")\n\nif not lc_img_has_tool and not raw_img_has_tool:\n    print(\"\\n  ğŸ”´ ê²°ë¡ : ì´ë¯¸ì§€ ì…ë ¥ì´ tool callingì„ ë°©í•´í•œë‹¤!\")\n    print(\"  â†’ ì‚¬íŒŒë¦¬ ì—ì´ì „íŠ¸ì—ì„œ tool callì´ ì•ˆ ë˜ëŠ” ì›ì¸ì€ ì´ë¯¸ì§€(multimodal) ì…ë ¥\")\nelif lc_img_has_tool and raw_img_has_tool:\n    print(\"\\n  ğŸŸ¢ ê²°ë¡ : ì´ë¯¸ì§€ í¬í•¨í•´ë„ tool calling ì •ìƒ ë™ì‘\")\n    print(\"  â†’ ì´ë¯¸ì§€ê°€ ì›ì¸ì´ ì•„ë‹˜, ë‹¤ë¥¸ ë³€ìˆ˜(í”„ë¡¬í”„íŠ¸/ë©”ì‹œì§€ êµ¬ì¡° ë“±) ì¡°ì‚¬ í•„ìš”\")\nelse:\n    print(f\"\\n  ğŸŸ¡ ê²°ë¡ : ë¶€ë¶„ì  ì°¨ì´ ë°œê²¬ â€” ì¶”ê°€ ì¡°ì‚¬ í•„ìš”\")\n    print(f\"  â†’ LangChain: {'ì •ìƒ' if lc_img_has_tool else 'ì‹¤íŒ¨'}\")\n    print(f\"  â†’ Raw HTTP: {'ì •ìƒ' if raw_img_has_tool else 'ì‹¤íŒ¨'}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T05:23:40.173349200Z",
     "start_time": "2026-02-17T05:23:16.334579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (base64 ê¸¸ì´: 512)\n",
      "\n",
      "============================================================\n",
      "[LangChain bind_tools + ì´ë¯¸ì§€]\n",
      "============================================================\n",
      "\n",
      "ğŸ“Œ type        : AIMessage\n",
      "ğŸ“Œ content     :\n",
      "Okay, let's see. The user is on a grid map, starting at (0,0), and needs to get to (2,1). The current position is (0,0), which is the bottom-left corner maybe? Wait, in grid coordinates, sometimes (0,0) is top-left, but the image shows a red dot at the bottom left and green at (2,1) maybe? Wait, the user says current position is (0,0), target is (2,1). So the grid is probably 0-based.\n",
      "\n",
      "First, I need to figure out the directions. The user is at (0,0), target is (2,1). So they need to move right 2\n",
      "ğŸ“Œ tool_calls  : [{'name': 'move', 'args': {'actions': [{'direction': 'RIGHT', 'steps': 2}, {'direction': 'UP', 'steps': 1}]}, 'id': 'chatcmpl-tool-98fcd48f971a63f1', 'type': 'tool_call'}]\n",
      "\n",
      "============================================================\n",
      "[Raw HTTP + ì´ë¯¸ì§€ â€” ì‚¬íŒŒë¦¬ ì—ì´ì „íŠ¸ ë™ì¼ êµ¬ì¡°]\n",
      "============================================================\n",
      "\n",
      "ğŸ“Œ status_code : 200\n",
      "ğŸ“Œ raw JSON    :\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"annotations\": null,\n",
      "        \"audio\": null,\n",
      "        \"content\": \"Okay, let's see. The user is on a grid map, currently at (0,0), and needs to get to (2,1). The move tool allows up to four actions, each being a direction (UP, DOWN, LEFT, RIGHT) with steps.\\n\\nFirst, I need to figure out the coordinates. Wait, in grid coordinates, sometimes (x,y) where x is horizontal and y is vertical. But the problem says current position is (0,0) and target is (2,1). So moving from (0,0) to (2,1) means moving right 2 steps and up 1 step. But wait, maybe the grid is oriented differently. Let me check the image description.\\n\\nThe user provided an image with a red dot at (0,0) and a green dot at (2,1). Wait, the image shows a grid where the red is at the bottom left, green is two to the right and one up. So assuming standard Cartesian coordinates where (0,0) is bottom left, moving right increases x, moving up increases y. So to get from (0,0) to (2,1), need to move right 2 steps and up 1 step.\\n\\nBut the move tool allows up to four actions. So the minimal steps would be two right and one up. But maybe the user wants to use the tool with four actions, but since the target is (2,1), maybe two right and one up. Wait, but the problem says \\\"ìµœëŒ€ 4ê°œ í–‰ë™ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰\\\" so maximum four actions. So the minimal path is three actions: right, right, up. But maybe the user expects to use four actions, but since the target is (2,1), three actions would suffice. Wait, but the problem says \\\"move ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì´ë™í•´\\\" so just need to get to (2,1). So the correct path is two rights and one up.\\n\\nWait, but in the grid, moving right from (0,0) would go to (1,0), then (2,0), then up to (2,1). So two right steps and one up step. So the actions would be:\\n\\nFirst action: direction RIGHT, steps 2 (to get to (2,0)), then direction UP, steps 1 (to (2,1)). But wait, the steps parameter is the number of steps in that direction. So moving RIGHT 2 steps would take you from (0,0) to (2,0), then UP 1 step to (2,1). So the actions array would have two elements: [ {direction: \\\"RIGHT\\\", steps: 2}, {direction: \\\"UP\\\", steps: 1} ].\\n\\nBut the problem says \\\"ìµœëŒ€ 4ê°œ í–‰ë™ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰\\\" so maybe the user can use up to four, but the minimal is two. However, the user might not want to overcomplicate. So the correct move sequence is two rights and one up. Wait, but in the grid, moving right 2 steps from (0,0) would be (2,0), then up 1 to (2,1). So yes, two actions.\\n\\nWait, but the problem says \\\"move ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì´ë™í•´\\\" so the assistant should generate the correct move commands. So the answer should be two actions: right 2 steps, then up 1 step.\\n\\nWait, but the tool's parameters require an array of actions. Each action is an object with direction and steps. So the correct JSON would be:\\n\\n{\\n  \\\"actions\\\": [\\n    {\\\"direction\\\": \\\"RIGHT\\\", \\\"steps\\\": 2},\\n    {\\\"direction\\\": \\\"UP\\\", \\\"steps\\\": 1}\\n  ]\\n}\\n\\nBut let me check if the coordinates are correct. If (0,0) is the starting point, moving right 2 steps would take you to x=2, y=0. Then moving up 1 step would take you to x=2, y=1. Which is the target. So that's correct.\\n\\nAlternatively, maybe the grid is oriented with (0,0) at the top left, but the image shows red at the bottom left, so probably (0,0) is bottom left, so moving up increases y. So yes, the path is right then up.\\n\\nTherefore, the correct tool call is two actions: right 2 steps, then up 1 step.\\n</think>\\n\\n\",\n",
      "        \"function_call\": null,\n",
      "        \"reasoning\": null,\n",
      "        \"reasoning_content\": null,\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"actions\\\": [{\\\"direction\\\": \\\"RIGHT\\\", \\\"steps\\\": 2}, {\\\"direction\\\": \\\"UP\\\", \\\"steps\\\": 1}]}\",\n",
      "              \"name\": \"move\"\n",
      "            },\n",
      "            \"id\": \"chatcmpl-tool-b2a46b11a016602e\",\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"stop_reason\": null,\n",
      "      \"token_ids\": null\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1771305808,\n",
      "  \"id\": \"chatcmpl-959a86fa94866392\",\n",
      "  \"kv_transfer_params\": null,\n",
      "  \"model\": \"qwen/qwen3-vl-4b-thinking-fp8\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"prompt_logprobs\": null,\n",
      "  \"prompt_token_ids\": null,\n",
      "  \"service_tier\": null,\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 966,\n",
      "    \"prompt_tokens\": 327,\n",
      "    \"prompt_tokens_details\": null,\n",
      "    \"total_tokens\": 1293\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "[ë¹„êµ ìš”ì•½: í…ìŠ¤íŠ¸ ì „ìš© (cell-8) vs ì´ë¯¸ì§€ í¬í•¨ (cell-9)]\n",
      "============================================================\n",
      "  ë°©ì‹                                   í…ìŠ¤íŠ¸ë§Œ        í…ìŠ¤íŠ¸+ì´ë¯¸ì§€\n",
      "  ------------------------------ ---------- --------------\n",
      "  LangChain bind_tools                    O              O\n",
      "  Raw HTTP                                O              O\n",
      "\n",
      "  ğŸŸ¢ ê²°ë¡ : ì´ë¯¸ì§€ í¬í•¨í•´ë„ tool calling ì •ìƒ ë™ì‘\n",
      "  â†’ ì´ë¯¸ì§€ê°€ ì›ì¸ì´ ì•„ë‹˜, ë‹¤ë¥¸ ë³€ìˆ˜(í”„ë¡¬í”„íŠ¸/ë©”ì‹œì§€ êµ¬ì¡° ë“±) ì¡°ì‚¬ í•„ìš”\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
